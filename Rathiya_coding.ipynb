{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rathiya-Jegan/Rathiya/blob/Rathiya-Jegan-branch-1/Rathiya_coding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_oQ2zIdOvvn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform thresholding segmentation and calculate metrics\n",
        "def thresholding_segmentation_and_metrics(image_path, ground_truth_path, loss):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, segmented_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_mask)  # Display the segmented image in black and white\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Process validation data\n",
        "validation_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "\n",
        "        # Load the corresponding loss value for this image\n",
        "        # Replace the following line with code to load the actual loss value\n",
        "        loss = 0.1  # Placeholder, replace with actual code\n",
        "\n",
        "        metrics = thresholding_segmentation_and_metrics(image_path, ground_truth_path, loss)\n",
        "        if metrics is not None:\n",
        "            validation_metrics['Accuracy'].append(metrics[0])\n",
        "            validation_metrics['Precision'].append(metrics[1])\n",
        "            validation_metrics['Recall'].append(metrics[2])\n",
        "            validation_metrics['F-Score'].append(metrics[3])\n",
        "            validation_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Process testing data\n",
        "testing_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "\n",
        "        # Load the corresponding loss value for this image\n",
        "        # Replace the following line with code to load the actual loss value\n",
        "        loss = 0.1  # Placeholder, replace with actual code\n",
        "\n",
        "        metrics = thresholding_segmentation_and_metrics(image_path, ground_truth_path, loss)\n",
        "        if metrics is not None:\n",
        "            testing_metrics['Accuracy'].append(metrics[0])\n",
        "            testing_metrics['Precision'].append(metrics[1])\n",
        "            testing_metrics['Recall'].append(metrics[2])\n",
        "            testing_metrics['F-Score'].append(metrics[3])\n",
        "            testing_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Display the metrics for validation and testing\n",
        "print(\"Validation Metrics:\")\n",
        "print(\"Accuracy: {:.2f}%\".format(np.mean(validation_metrics['Accuracy'])))\n",
        "print(\"Precision: {:.2f}%\".format(np.mean(validation_metrics['Precision'])))\n",
        "print(\"Recall: {:.2f}%\".format(np.mean(validation_metrics['Recall'])))\n",
        "print(\"F-Score: {:.2f}%\".format(np.mean(validation_metrics['F-Score'])))\n",
        "print(\"Loss: {:.2f}\".format(np.mean(validation_metrics['Loss'])))\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(\"Accuracy: {:.2f}%\".format(np.mean(testing_metrics['Accuracy'])))\n",
        "print(\"Precision: {:.2f}%\".format(np.mean(testing_metrics['Precision'])))\n",
        "print(\"Recall: {:.2f}%\".format(np.mean(testing_metrics['Recall'])))\n",
        "print(\"F-Score: {:.2f}%\".format(np.mean(testing_metrics['F-Score'])))\n",
        "print(\"Loss: {:.2f}\".format(np.mean(testing_metrics['Loss'])))\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(validation_metrics['Accuracy'], label=\"Validation Accuracy\")\n",
        "plt.plot(testing_metrics['Accuracy'], label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(validation_metrics['F-Score'], label=\"Validation F-Score\")\n",
        "plt.plot(testing_metrics['F-Score'], label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(validation_metrics['Loss'], label=\"Validation Loss\")\n",
        "plt.plot(testing_metrics['Loss'], label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(validation_metrics['Precision'], label=\"Validation Precision\")\n",
        "plt.plot(testing_metrics['Precision'], label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(validation_metrics['Recall'], label=\"Validation Recall\")\n",
        "plt.plot(testing_metrics['Recall'], label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git -y\n"
      ],
      "metadata": {
        "id": "Odu_u9fiS_aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jHPFkOgikSP"
      },
      "outputs": [],
      "source": [
        "!git config --global user.name \"Rathiya-Jegan\"\n",
        "!git config --global user.email \"vr.rathiya03@gmail.com\"\n",
        "!rm -rf Rathiya\n",
        "\n",
        "!git clone https://github.com/Rathiya-Jegan/Rathiya.git\n",
        "import os\n",
        "os.listdir()\n",
        "!cp rathiya_new_phd.ipynb Rathiya/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di_tqDMU6Fh4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def gaussian_blur(image, sigma=1):\n",
        "    return cv2.GaussianBlur(image, (0, 0), sigma)\n",
        "\n",
        "def kmeans_segmentation(image, k):\n",
        "    reshaped_image = image.reshape((-1, 3))\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.labels_.reshape(image.shape[:2])\n",
        "    return segmented_image\n",
        "\n",
        "def extract_features(image):\n",
        "    # Implement feature extraction logic for MDSG-SE block\n",
        "    # ...\n",
        "\n",
        "def train_classifier(X_train, y_train):\n",
        "    classifier = SVC(kernel='linear')\n",
        "    classifier.fit(X_train, y_train)\n",
        "    return classifier\n",
        "\n",
        "def main(folder_path):\n",
        "    # Load images from the specified folder\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        original_image = cv2.imread(image_path)\n",
        "\n",
        "        # Apply Gaussian blur pre-processing\n",
        "        blurred_image = gaussian_blur(original_image)\n",
        "\n",
        "        # Apply K-means segmentation\n",
        "        k = 3  # You can adjust the number of clusters as needed\n",
        "        segmented_image = kmeans_segmentation(blurred_image, k)\n",
        "\n",
        "        # Extract features using MDSG-SE block\n",
        "        features = extract_features(segmented_image)\n",
        "\n",
        "        # Append the features and corresponding label\n",
        "        X.append(features)\n",
        "        y.append(label)  # Assign the appropriate label\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier = train_classifier(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    folder_path = input(\"Enter the folder path containing images: \")\n",
        "    main(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPKSxLMFP17B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiI11v3C-I76"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F23cnVF63KD0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual code)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}%\")\n",
        "    print(f\"Recall: {recall:.2f}%\")\n",
        "    print(f\"F-Score: {f_score:.2f}%\")\n",
        "    print(f\"Loss: {loss:.2f}\")  # Print the loss value\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Process validation data\n",
        "validation_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        metrics = watershed_segmentation_and_metrics(image_path, ground_truth_path)\n",
        "        if metrics is not None:\n",
        "            validation_metrics['Accuracy'].append(metrics[0])\n",
        "            validation_metrics['Precision'].append(metrics[1])\n",
        "            validation_metrics['Recall'].append(metrics[2])\n",
        "            validation_metrics['F-Score'].append(metrics[3])\n",
        "            validation_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Process testing data\n",
        "testing_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        metrics = watershed_segmentation_and_metrics(image_path, ground_truth_path)\n",
        "        if metrics is not None:\n",
        "            testing_metrics['Accuracy'].append(metrics[0])\n",
        "            testing_metrics['Precision'].append(metrics[1])\n",
        "            testing_metrics['Recall'].append(metrics[2])\n",
        "            testing_metrics['F-Score'].append(metrics[3])\n",
        "            testing_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(validation_metrics['Accuracy'], label=\"Validation Accuracy\")\n",
        "plt.plot(testing_metrics['Accuracy'], label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(validation_metrics['F-Score'], label=\"Validation F-Score\")\n",
        "plt.plot(testing_metrics['F-Score'], label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(validation_metrics['Loss'], label=\"Validation Loss\")\n",
        "plt.plot(testing_metrics['Loss'], label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(validation_metrics['Precision'], label=\"Validation Precision\")\n",
        "plt.plot(testing_metrics['Precision'], label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(validation_metrics['Recall'], label=\"Validation Recall\")\n",
        "plt.plot(testing_metrics['Recall'], label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yngkY82F6LXc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5vCrdkL63Pd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Lists to store individual image metrics\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "\n",
        "    # Display the original and segmented images (commented out for faster execution)\n",
        "    # cv2_imshow(image)\n",
        "    # cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(val_accuracy_list, label=\"Validation Accuracy\")\n",
        "plt.plot(test_accuracy_list, label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(val_fscore_list, label=\"Validation F-Score\")\n",
        "plt.plot(test_fscore_list, label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
        "plt.plot(test_loss_list, label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(val_precision_list, label=\"Validation Precision\")\n",
        "plt.plot(test_precision_list, label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(val_recall_list, label=\"Validation Recall\")\n",
        "plt.plot(test_recall_list, label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkKQ2gnw_Oku"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 1 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "\n",
        "# Print metrics\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    avg_validating_precision = sum(validating_precisions) / len(validating_precisions)\n",
        "    avg_validating_recall = sum(validating_recalls) / len(validating_recalls)\n",
        "    avg_validating_f_score = sum(validating_f_scores) / len(validating_f_scores)\n",
        "    avg_validating_loss = sum(validating_losses) / len(validating_losses)\n",
        "\n",
        "    print(f\"Validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "    print(f\"Validation Data Precision: {avg_validating_precision:.2f}\")\n",
        "    print(f\"Validation Data Recall: {avg_validating_recall:.2f}\")\n",
        "    print(f\"Validation Data F-Score: {avg_validating_f_score:.2f}\")\n",
        "    print(f\"Validation Data Loss: {avg_validating_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No validation data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    avg_testing_precision = sum(testing_precisions) / len(testing_precisions)\n",
        "    avg_testing_recall = sum(testing_recalls) / len(testing_recalls)\n",
        "    avg_testing_f_score = sum(testing_f_scores) / len(testing_f_scores)\n",
        "    avg_testing_loss = sum(testing_losses) / len(testing_losses)\n",
        "\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "    print(f\"Testing Data Precision: {avg_testing_precision:.2f}\")\n",
        "    print(f\"Testing Data Recall: {avg_testing_recall:.2f}\")\n",
        "    print(f\"Testing Data F-Score: {avg_testing_f_score:.2f}\")\n",
        "    print(f\"Testing Data Loss: {avg_testing_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "# Plotting function\n",
        "def plot_metrics(validation_metrics, testing_metrics, metric_name):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(validation_metrics, label='Validation', marker='o')\n",
        "    plt.plot(testing_metrics, label='Testing', marker='x')\n",
        "    plt.xlabel('Image Index')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend()\n",
        "    plt.title(f'Validation vs Testing {metric_name}')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the metrics\n",
        "if validating_accuracies and testing_accuracies:\n",
        "    plot_metrics(validating_accuracies, testing_accuracies, 'Accuracy')\n",
        "\n",
        "if validating_recalls and testing_recalls:\n",
        "    plot_metrics(validating_recalls, testing_recalls, 'Recall')\n",
        "\n",
        "if validating_f_scores and testing_f_scores:\n",
        "    plot_metrics(validating_f_scores, testing_f_scores, 'F-Score')\n",
        "\n",
        "if validating_losses and testing_losses:\n",
        "    plot_metrics(validating_losses, testing_losses, 'Loss')\n",
        "\n",
        "if validating_precisions and testing_precisions:\n",
        "    plot_metrics(validating_precisions, testing_precisions, 'Precision')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7koFCdv-4YZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf spot'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf spot'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA5Up2WgiaFh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_7rHoZ1jo37q"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image from your Colab environment\n",
        "image_path = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl new/leaf curl30.jpg'  # Replace with the path to your image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Apply Gaussian blur\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Convert the Gaussian blurred image to grayscale\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the grayscale Gaussian blurred image\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(gaussian_blur_gray, cmap='gray')  # Specify the colormap as 'gray'\n",
        "#plt.title('Gaussian Blur (Grayscale)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywzOm-ul_sN6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "#train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl new'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "val_data_directory='/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "#training_accuracies = []\n",
        "#for filename in os.listdir(train_data_directory):\n",
        " #   if filename.endswith('.jpg'):\n",
        " #       image_path = os.path.join(train_data_directory, filename)\n",
        " #       ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        " #       accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        " #       if accuracy is not None:\n",
        " #           training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "   if filename.endswith('.jpg'):\n",
        "      image_path = os.path.join(val_data_directory, filename)\n",
        "      ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "      accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "      if accuracy is not None:\n",
        "          validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "#if training_accuracies:\n",
        "   # avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    #print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "#else:\n",
        " #   print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1s-6nDcLENr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "#train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "# Function to perform thresholding segmentation and calculate accuracy\n",
        "def thresholding_segmentation_and_accuracy(image_path, ground_truth_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, segmented_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_mask)  # Display the segmented image in black and white\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "#training_accuracies = []\n",
        "#for filename in os.listdir(train_data_directory):\n",
        " #   if filename.endswith('.jpg'):\n",
        "     #   image_path = os.path.join(train_data_directory, filename)\n",
        "    #   ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "      #  accuracy = thresholding_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "      #  if accuracy is not None:\n",
        "        #    training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = thresholding_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = thresholding_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "# Calculate and print average accuracies\n",
        "#if training_accuracies:\n",
        " #   avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "   # print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "#else:\n",
        "   # print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validating Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IK7gUCahNtD9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/leaf curl'\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/leaf curl'\n",
        "\n",
        "# Function to perform watershed segmentation and calculate accuracy\n",
        "def watershed_segmentation_and_accuracy(image_path, ground_truth_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "#training_accuracies = []\n",
        "#for filename in os.listdir(train_data_directory):\n",
        "    #if filename.endswith('.jpg'):\n",
        "        #image_path = os.path.join(train_data_directory, filename)\n",
        "        #ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        #accuracy = watershed_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        #if accuracy is not None:\n",
        "            #training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = watershed_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = watershed_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "# Calculate and print average accuracies\n",
        "#if training_accuracies:\n",
        "    #avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    #print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "#else:\n",
        "    #print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validating Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE9SfcNjE29J"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf curl'\n",
        "val_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/val/leaf curl'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validating Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eonG4yqHASql"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psu0VywGAe9T"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/whitefly'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/whitefly'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/whitefly'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVfi-PWDBfiK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/whitefly'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/whitefly'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/whitefly'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDJ2QaEEB_KD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/yellowish'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in3yFioYDmPN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-uEki98bDmiu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/yellowish'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O__fI7j2-O7C"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 1 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Function to display the original image, segmented image, and Gaussian blurred image\n",
        "def display_images(image, segmented_image, gaussian_blur_gray):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Segmented Image\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Segmented Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Gaussian Blurred Image (Grayscale)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(gaussian_blur_gray, cmap='gray')\n",
        "    plt.title('Gaussian Blur (Grayscale)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "\n",
        "# Print metrics\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    avg_validating_precision = sum(validating_precisions) / len(validating_precisions)\n",
        "    avg_validating_recall = sum(validating_recalls) / len(validating_recalls)\n",
        "    avg_validating_f_score = sum(validating_f_scores) / len(validating_f_scores)\n",
        "    avg_validating_loss = sum(validating_losses) / len(validating_losses)\n",
        "\n",
        "    print(f\"Validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "    print(f\"Validation Data Precision: {avg_validating_precision:.2f}\")\n",
        "    print(f\"Validation Data Recall: {avg_validating_recall:.2f}\")\n",
        "    print(f\"Validation Data F-Score: {avg_validating_f_score:.2f}\")\n",
        "    print(f\"Validation Data Loss: {avg_validating_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No validation data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    avg_testing_precision = sum(testing_precisions) / len(testing_precisions)\n",
        "    avg_testing_recall = sum(testing_recalls) / len(testing_recalls)\n",
        "    avg_testing_f_score = sum(testing_f_scores) / len(testing_f_scores)\n",
        "    avg_testing_loss = sum(testing_losses) / len(testing_losses)\n",
        "\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "    print(f\"Testing Data Precision: {avg_testing_precision:.2f}\")\n",
        "    print(f\"Testing Data Recall: {avg_testing_recall:.2f}\")\n",
        "    print(f\"Testing Data F-Score: {avg_testing_f_score:.2f}\")\n",
        "    print(f\"Testing Data Loss: {avg_testing_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "# Plotting function\n",
        "def plot_metrics(validation_metrics, testing_metrics, metric_name):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(validation_metrics, label='Validation', marker='o')\n",
        "    plt.plot(testing_metrics, label='Testing', marker='x')\n",
        "    plt.xlabel('Image Index')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend()\n",
        "    plt.title(f'Validation vs Testing {metric_name}')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the metrics\n",
        "if validating_accuracies and testing_accuracies:\n",
        "    plot_metrics(validating_accuracies, testing_accuracies, 'Accuracy')\n",
        "\n",
        "if validating_recalls and testing_recalls:\n",
        "    plot_metrics(validating_recalls, testing_recalls, 'Recall')\n",
        "\n",
        "if validating_f_scores and testing_f_scores:\n",
        "    plot_metrics(validating_f_scores, testing_f_scores, 'F-Score')\n",
        "\n",
        "if validating_losses and testing_losses:\n",
        "    plot_metrics(validating_losses, testing_losses, 'Loss')\n",
        "\n",
        "if validating_precisions and testing_precisions:\n",
        "    plot_metrics(validating_precisions, testing_precisions, 'Precision')\n",
        "\n",
        "# Load an image from your Colab environment for Gaussian Blur pre-processing\n",
        "image_path = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf curl new/leaf curl90.jpg'  # Replace with your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Apply Gaussian blur\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Convert the Gaussian blurred image to grayscale\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the grayscale Gaussian blurred image\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(gaussian_blur_gray, cmap='gray')  # Specify the colormap as 'gray'\n",
        "plt.title('Gaussian Blur (Grayscale)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the original image, segmented image, and Gaussian-blurred image for a specific image\n",
        "sample_image_path = '/content/drive/MyDrive/preprocessed/val/yellowish/sample.jpg'  # Replace with your image path\n",
        "sample_ground_truth_path = '/content/drive/MyDrive/preprocessed/val/yellowish/sample_mask.png'  # Replace with ground truth path\n",
        "\n",
        "image = cv2.imread(sample_image_path)\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "accuracy, _, _, _, _ = kmeans_segmentation_and_metrics(sample_image_path, sample_ground_truth_path, num_clusters=2)\n",
        "\n",
        "if accuracy is not None:\n",
        "    display_images(image, segmented_image, gaussian_blur_gray)\n",
        "else:\n",
        "    print(\"Image segmentation failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X4yTc3RtfV6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Lists to store individual image metrics\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "\n",
        "    # Display the original and segmented images (commented out for faster execution)\n",
        "    # cv2_imshow(image)\n",
        "    # cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(val_accuracy_list, label=\"Validation Accuracy\")\n",
        "plt.plot(test_accuracy_list, label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(val_fscore_list, label=\"Validation F-Score\")\n",
        "plt.plot(test_fscore_list, label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
        "plt.plot(test_loss_list, label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(val_precision_list, label=\"Validation Precision\")\n",
        "plt.plot(test_precision_list, label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(val_recall_list, label=\"Validation Recall\")\n",
        "plt.plot(test_recall_list, label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKTB4dz8u-Ml"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Lists to store individual image metrics and segmented images\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "val_segmented_images = []  # Store segmented images\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "test_segmented_images = []  # Store segmented images\n",
        "\n",
        "# Function to display images (original and segmented)\n",
        "def display_images(original, segmented):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Original Image\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Segmented Image\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "        val_segmented_images.append(segmented_image)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "        test_segmented_images.append(segmented_image)\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    display_images(image, segmented_image)\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-sWniFnxmib"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Lists to store individual image metrics and segmented images\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "val_segmented_images = []  # Store segmented images\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "test_segmented_images = []  # Store segmented images\n",
        "\n",
        "# Function to display images (original and segmented)\n",
        "def display_images(original, segmented):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    #plt.subplot(1, 2, 1)\n",
        "    #plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "    #plt.title(\"Original Image\")\n",
        "    #plt.axis('off')  # Remove axis\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
        "    #plt.title(\"Segmented Image\")\n",
        "    plt.axis('off')  # Remove axis\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "        val_segmented_images.append(segmented_image)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "        test_segmented_images.append(segmented_image)\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    display_images(image, segmented_image)\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVDM6yLb4PaY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf curl'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3npF8vU63qW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 100 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss, segmented_image\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "validating_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "            validating_segmented_images.append(segmented_image)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "testing_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "            testing_segmented_images.append(segmented_image)\n",
        "\n",
        "# Create separate line graphs for comparing metrics\n",
        "metrics_labels = ['Accuracy', 'Precision', 'Recall', 'F-Score', 'Loss']\n",
        "\n",
        "# Validation vs. Testing Recall\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_recalls, label='Validation Recall', marker='o', linestyle='-')\n",
        "plt.plot(testing_recalls, label='Testing Recall', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Recall (%)')\n",
        "plt.title('Validation vs. Testing Recall Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_recalls)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing F-Score\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_f_scores, label='Validation F-Score', marker='o', linestyle='-')\n",
        "plt.plot(testing_f_scores, label='Testing F-Score', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('F-Score (%)')\n",
        "plt.title('Validation vs. Testing F-Score Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_f_scores)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing Precision\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_precisions, label='Validation Precision', marker='o', linestyle='-')\n",
        "plt.plot(testing_precisions, label='Testing Precision', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Precision (%)')\n",
        "plt.title('Validation vs. Testing Precision Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_precisions)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_accuracies, label='Validation Accuracy', marker='o', linestyle='-')\n",
        "plt.plot(testing_accuracies, label='Testing Accuracy', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Validation vs. Testing Accuracy Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_accuracies)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_losses, label='Validation Loss', marker='o', linestyle='-')\n",
        "plt.plot(testing_losses, label='Testing Loss', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation vs. Testing Loss Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_losses)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Display some segmented images\n",
        "num_images_to_display = 5\n",
        "for i in range(min(num_images_to_display, len(validating_segmented_images))):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(validating_segmented_images[i], cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Segmented Image {i+1}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRxaePDR9-q9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 100 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss, segmented_image\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "validating_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "            validating_segmented_images.append(segmented_image)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "testing_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "            testing_segmented_images.append(segmented_image)\n",
        "\n",
        "# Display all segmented images\n",
        "for i, segmented_image in enumerate(validating_segmented_images):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Segmented Image {i+1}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display metrics in percentage values\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(validating_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(validating_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(validating_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(validating_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(validating_losses):.2f}%\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(testing_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(testing_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(testing_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(testing_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(testing_losses):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIU-SHUPBF5D"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 100 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss, segmented_image\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "validating_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "            validating_segmented_images.append(segmented_image)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "testing_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "            testing_segmented_images.append(segmented_image)\n",
        "\n",
        "# Display all segmented images (Validation)\n",
        "for i, segmented_image in enumerate(validating_segmented_images):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Validation Segmented Image {i+1}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display all segmented images (Testing)\n",
        "for i, segmented_image in enumerate(testing_segmented_images):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Testing Segmented Image {i+1}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display metrics in percentage values\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(validating_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(validating_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(validating_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(validating_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(validating_losses):.2f}%\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(testing_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(testing_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(testing_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(testing_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(testing_losses):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x44J3lmFBmh"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python numpy deap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFT0VXUiotM2"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Step 1: Load and preprocess segmented images\n",
        "\n",
        "def load_and_preprocess_data(data_dir):\n",
        "    image_data = []\n",
        "    labels = []\n",
        "\n",
        "    for class_name in os.listdir(data_dir):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            for image_name in os.listdir(class_dir):\n",
        "                if image_name.endswith(\".jpg\"):\n",
        "                    image_path = os.path.join(class_dir, image_name)\n",
        "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    # Resize the image to a fixed size (e.g., 64x64)\n",
        "                    image = cv2.resize(image, (64, 64))\n",
        "                    image_data.append(image.flatten())  # Flatten the image matrix\n",
        "                    labels.append(class_name)\n",
        "\n",
        "    return np.array(image_data), np.array(labels)\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/output/Kmeans/healthy'\n",
        "if not os.path.exists(data_dir):\n",
        "    print(f\"Directory '{data_dir}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "X, y = load_and_preprocess_data(data_dir)\n",
        "\n",
        "if len(X) == 0:\n",
        "    print(\"No data loaded. Please check your data directory.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 3: Create an SVM classifier\n",
        "\n",
        "svm_classifier = SVC(kernel='linear', C=1)\n",
        "\n",
        "# Step 4: Train the SVM classifier\n",
        "\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make predictions on the test data\n",
        "\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the classifier\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWiREVCfrgBc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import os\n",
        "\n",
        "# Step 1: Load and preprocess segmented images\n",
        "\n",
        "def load_and_preprocess_data(data_dir):\n",
        "    image_data = []\n",
        "    labels = []\n",
        "\n",
        "    for class_name in os.listdir(data_dir):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            for image_name in os.listdir(class_dir):\n",
        "                if image_name.endswith(\".jpg\"):\n",
        "                    image_path = os.path.join(class_dir, image_name)\n",
        "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    # Resize the image to a fixed size (e.g., 64x64)\n",
        "                    image = cv2.resize(image, (64, 64))\n",
        "                    image_data.append(image.flatten())  # Flatten the image matrix\n",
        "                    labels.append(class_name)\n",
        "\n",
        "    return np.array(image_data), np.array(labels)\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/output/Kmeans/healthy'\n",
        "if not os.path.exists(data_dir):\n",
        "    print(f\"Directory '{data_dir}' does not exist.\")\n",
        "    exit()\n",
        "\n",
        "X, y = load_and_preprocess_data(data_dir)\n",
        "\n",
        "if len(X) == 0:\n",
        "    print(\"No data loaded. Please check your data directory.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Step 3: Hyperparameter tuning using GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],  # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto', 1, 0.1],  # Kernel coefficient for 'rbf' and 'poly'\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_svm_classifier = grid_search.best_estimator_\n",
        "\n",
        "# Step 4: Train the SVM classifier with the best parameters\n",
        "\n",
        "best_svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make predictions on the test data\n",
        "\n",
        "y_pred = best_svm_classifier.predict(X_test)\n",
        "\n",
        "# Step 6: Evaluate the classifier\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB4MYSUM2c5m"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/preprocessed/train/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSzN3lpu9EuC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image from your Colab environment\n",
        "image_path = '/content/drive/MyDrive/Chili_Plant_Disease/train/yellowish/yellowisha22.jpg'  # Replace with the path to your image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Apply Gaussian blur\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Convert the Gaussian blurred image to grayscale\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the grayscale Gaussian blurred image\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(gaussian_blur_gray, cmap='gray')  # Specify the colormap as 'gray'\n",
        "#plt.title('Gaussian Blur (Grayscale)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzOJryPyB2p7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score (ground_truth.flatten() // 255,  segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuKtgFkWxDPm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Ensure both images have the same dimensions\n",
        "    if image.shape[:2] != ground_truth.shape:\n",
        "        print(f\"Error: Image dimensions do not match ground truth dimensions. Check: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Resize the segmented mask to match ground truth dimensions\n",
        "    segmented_mask = cv2.resize(segmented_mask, (ground_truth.shape[1], ground_truth.shape[0]))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    # cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERlbgL_73sCn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Ensure both images have the same dimensions\n",
        "    if image.shape[:2] != ground_truth.shape:\n",
        "        print(f\"Error: Image dimensions do not match ground truth dimensions. Check: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Resize the segmented mask to match ground truth dimensions\n",
        "    segmented_mask = cv2.resize(segmented_mask, (ground_truth.shape[1], ground_truth.shape[0]))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Path to your single image and its corresponding ground truth mask\n",
        "image_path = '/content/drive/MyDrive/leaf spot/59.jpg'\n",
        "#ground_truth_path = '/content/drive/MyDrive/leaf spot/59_mask.png'\n",
        "\n",
        "# Number of clusters for K-means\n",
        "num_clusters = 4\n",
        "\n",
        "# Call the function with the single image\n",
        "accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters)\n",
        "\n",
        "if accuracy is not None:\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"Image processing failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpIVsvPCkxac"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8n158NOsDJS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nzrDHn3w99A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier (Multinomial Naive Bayes for image data)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Had70CvpxqRF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apoRaGE9yclb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Logistic Regression classifier\n",
        "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WZGK62Tz5Jb"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-fuzzy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE1I4PZKzvod"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Define fuzzy logic rules (simplified example)\n",
        "def fuzzy_logic_classifier(input_data):\n",
        "    # Define membership functions for input data\n",
        "    input_membership = fuzz.trimf(input_data, [0, 0, 255])\n",
        "\n",
        "    # Define fuzzy rules (simplified)\n",
        "    # Rule 1: If input_data is low, then output is \"Not Likely\"\n",
        "    # Rule 2: If input_data is high, then output is \"Highly Likely\"\n",
        "    output_membership = np.zeros_like(input_data)\n",
        "    output_membership[input_data > 128] = 1\n",
        "\n",
        "    return output_membership\n",
        "\n",
        "# Step 4: Apply fuzzy logic to classify images\n",
        "y_pred = np.array([fuzzy_logic_classifier(image.flatten()) for image in X_test])\n",
        "\n",
        "# Step 5: Define the fuzzy output as crisp labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Step 6: Evaluate the classifier (crisp labels)\n",
        "accuracy = accuracy_score(y_test, y_pred_labels)\n",
        "classification_rep = classification_report(y_test, y_pred_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UefnqOC1Kxn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Create the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(100, 100)),  # Flatten the 2D image to a 1D vector\n",
        "    keras.layers.Dense(128, activation='relu'),    # Fully connected layer with 128 units and ReLU activation\n",
        "    keras.layers.Dense(10, activation='softmax')   # Output layer with 10 units (assuming 10 classes) and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the neural network\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Step 6: Make predictions and generate a classification report\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc_er1l-5d3j"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train an SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions using the SVM classifier\n",
        "svm_predictions = svm_classifier.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Train a Decision Tree classifier on all training data\n",
        "decision_tree_classifier = DecisionTreeClassifier()\n",
        "decision_tree_classifier.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 6: Combine the SVM and Decision Tree classifiers\n",
        "def hybrid_classifier(image):\n",
        "    svm_result = svm_classifier.predict(image.reshape(1, -1))\n",
        "    return decision_tree_classifier.predict(image.reshape(1, -1))\n",
        "\n",
        "# Step 7: Evaluate the hybrid classifier on the test set\n",
        "hybrid_predictions = np.array([hybrid_classifier(image) for image in X_test])\n",
        "accuracy = accuracy_score(y_test, hybrid_predictions)\n",
        "classification_rep = classification_report(y_test, hybrid_predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HflQCtD-YxNZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Function to create and train the neural network model\n",
        "def train_neural_network(X_train, y_train, num_epochs=10, batch_size=32):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(100, 100)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "# Number of runs and storage for accuracy values\n",
        "num_runs = 10\n",
        "accuracies = []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    print(f\"Run {run + 1}/{num_runs}\")\n",
        "    images, labels = load_and_preprocess_data(data_directory)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_neural_network(X_train, y_train)\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    accuracies.append(test_accuracy)\n",
        "\n",
        "# Plot the accuracy line graph\n",
        "plt.plot(range(1, num_runs + 1), accuracies, marker='o', linestyle='-')\n",
        "plt.xlabel('Run')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Test Accuracy vs. Run')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5LKW6aTa0p0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Define fuzzy logic rules (simplified example)\n",
        "def fuzzy_logic_classifier(input_data):\n",
        "    # Define membership functions for input data\n",
        "    input_membership = fuzz.trimf(input_data, [0, 0, 255])\n",
        "\n",
        "    # Define fuzzy rules (simplified)\n",
        "    # Rule 1: If input_data is low, then output is \"Not Likely\"\n",
        "    # Rule 2: If input_data is high, then output is \"Highly Likely\"\n",
        "    output_membership = np.zeros_like(input_data)\n",
        "    output_membership[input_data > 128] = 1\n",
        "\n",
        "    return output_membership\n",
        "\n",
        "# Step 4: Apply fuzzy logic to classify images and store the fuzzy outputs\n",
        "fuzzy_outputs = [fuzzy_logic_classifier(image.flatten()) for image in X_test]\n",
        "\n",
        "# Step 5: Visualize fuzzy outputs for a few test images\n",
        "num_images_to_visualize = 100\n",
        "\n",
        "for i in range(num_images_to_visualize):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # Input image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow (X_test[i], cmap='gray')\n",
        "    plt.title('Input Image')\n",
        "\n",
        "    # Fuzzy outputs\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(fuzzy_outputs[i])\n",
        "    plt.title('Fuzzy Outputs')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Step 6: Convert fuzzy outputs to crisp labels (e.g., using defuzzification)\n",
        "\n",
        "# Step 7: Evaluate the classifier (crisp labels) as in your previous code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEp5n0tHBf_d"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the segmented image\n",
        "segmented_image = cv2.imread('/content/drive/MyDrive/Kmeans/healthy/test/1.jpg')\n",
        "\n",
        "# Convert the segmented image to the HSV color space (optional but often used for color analysis)\n",
        "hsv_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define the number of bins for the histogram\n",
        "num_bins = 256  # You can adjust this value as needed\n",
        "\n",
        "# Compute the histogram for each channel (Hue, Saturation, and Value)\n",
        "hist_hue = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 256])\n",
        "hist_saturation = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])\n",
        "hist_value = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(131)\n",
        "plt.plot(hist_hue, color='b')\n",
        "plt.title('Hue Histogram')\n",
        "plt.subplot(132)\n",
        "plt.plot(hist_saturation, color='g')\n",
        "plt.title('Saturation Histogram')\n",
        "plt.subplot(133)\n",
        "plt.plot(hist_value, color='r')\n",
        "plt.title('Value Histogram')\n",
        "plt.xlim([0, 256])\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4rTjIOtB9kf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the segmented image\n",
        "segmented_image = cv2.imread('/content/drive/MyDrive/Kmeans/healthy/test/11.jpg')\n",
        "\n",
        "# Convert the segmented image to the HSV color space\n",
        "hsv_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define the number of bins for the histogram\n",
        "num_bins = 256\n",
        "\n",
        "# Compute the histogram for each channel (Hue, Saturation, and Value)\n",
        "hist_hue = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 256])\n",
        "hist_saturation = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])\n",
        "hist_value = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(131)\n",
        "plt.plot(hist_hue, color='b')\n",
        "plt.title('Hue Histogram')\n",
        "plt.subplot(132)\n",
        "plt.plot(hist_saturation, color='g')\n",
        "plt.title('Saturation Histogram')\n",
        "plt.subplot(133)\n",
        "plt.plot(hist_value, color='r')\n",
        "plt.title('Value Histogram')\n",
        "plt.xlim([0, 256])\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the segmented image\n",
        "plt.figure()\n",
        "plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Segmented Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80fxJHGVEK5g"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrJZ4I-eELxz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the segmented image\n",
        "segmented_image = cv2.imread('/content/drive/MyDrive/Kmeans/healthy/test/11.jpg')\n",
        "\n",
        "# Convert the segmented image to the HSV color space\n",
        "hsv_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define the number of bins for the histogram\n",
        "num_bins = 256\n",
        "\n",
        "# Compute the histogram for each channel (Hue, Saturation, and Value)\n",
        "hist_hue = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 256])\n",
        "hist_saturation = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])\n",
        "hist_value = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(131)\n",
        "plt.plot(hist_hue, color='b')\n",
        "plt.title('Hue Histogram')\n",
        "plt.subplot(132)\n",
        "plt.plot(hist_saturation, color='g')\n",
        "plt.title('Saturation Histogram')\n",
        "plt.subplot(133)\n",
        "plt.plot(hist_value, color='r')\n",
        "plt.title('Value Histogram')\n",
        "plt.xlim([0, 256])\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the segmented image\n",
        "plt.figure()\n",
        "plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Segmented Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3by05sgaZeK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Directory containing segmented images\n",
        "segmented_dir = '/content/drive/MyDrive/Kmeans/yellowish/train'\n",
        "\n",
        "# Initialize lists to store shape features\n",
        "areas = []\n",
        "perimeters = []\n",
        "circularities = []\n",
        "\n",
        "# Loop through segmented images\n",
        "for filename in os.listdir(segmented_dir):\n",
        "    if filename.endswith('.jpg'):\n",
        "        # Load segmented image\n",
        "        segmented_image = cv2.imread(os.path.join(segmented_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Find contours in the segmented image\n",
        "        contours, _ = cv2.findContours(segmented_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Initialize variables to store shape features for this image\n",
        "        area = 0\n",
        "        perimeter = 0\n",
        "        circularity = 0\n",
        "\n",
        "        # Calculate shape features for each contour (assuming only one object per image)\n",
        "        if contours:\n",
        "            contour = contours[0]\n",
        "            area = cv2.contourArea(contour)\n",
        "            perimeter = cv2.arcLength(contour, True)\n",
        "            circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "        # Append shape features to the respective lists\n",
        "        areas.append(area)\n",
        "        perimeters.append(perimeter)\n",
        "        circularities.append(circularity)\n",
        "\n",
        "# Convert shape features to NumPy arrays\n",
        "areas = np.array(areas)\n",
        "perimeters = np.array(perimeters)\n",
        "circularities = np.array(circularities)\n",
        "\n",
        "# Print or use the extracted shape features as needed\n",
        "print(f\"Number of images processed: {len(areas)}\")\n",
        "print(f\"Mean Area: {np.mean(areas)}\")\n",
        "print(f\"Mean Perimeter: {np.mean(perimeters)}\")\n",
        "print(f\"Mean Circularity: {np.mean(circularities)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL07VZJlqwuQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sln89iYIrMot"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset with shape feature extraction\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    areas = []\n",
        "    perimeters = []\n",
        "    circularities = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                # Shape feature extraction\n",
        "                contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                area = 0\n",
        "                perimeter = 0\n",
        "                circularity = 0\n",
        "\n",
        "                if contours:\n",
        "                    contour = contours[0]\n",
        "                    area = cv2.contourArea(contour)\n",
        "                    perimeter = cv2.arcLength(contour, True)\n",
        "                    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                areas.append(area)\n",
        "                perimeters.append(perimeter)\n",
        "                circularities.append(circularity)\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(areas), np.array(perimeters), np.array(circularities)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels, areas, perimeters, circularities = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Combine shape features with flattened image pixels\n",
        "combined_features = np.column_stack((images.reshape(len(images), -1), areas, perimeters, circularities))\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjA4muAnrh0k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset with shape feature extraction\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    areas = []\n",
        "    perimeters = []\n",
        "    circularities = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                # Shape feature extraction\n",
        "                contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                area = 0\n",
        "                perimeter = 0\n",
        "                circularity = 0\n",
        "\n",
        "                if contours:\n",
        "                    contour = contours[0]\n",
        "                    area = cv2.contourArea(contour)\n",
        "                    perimeter = cv2.arcLength(contour, True)\n",
        "                    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "                # Append shape features to the respective lists\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                areas.append(area)\n",
        "                perimeters.append(perimeter)\n",
        "                circularities.append(circularity)\n",
        "\n",
        "                # Display area, perimeter, and circularity for this image\n",
        "                print(f\"Image: {filename}\")\n",
        "                print(f\"Area: {area}\")\n",
        "                print(f\"Perimeter: {perimeter}\")\n",
        "                print(f\"Circularity: {circularity}\\n\")\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(areas), np.array(perimeters), np.array(circularities)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels, areas, perimeters, circularities = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Combine shape features with flattened image pixels\n",
        "combined_features = np.column_stack((images.reshape(len(images), -1), areas, perimeters, circularities))\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLZWvXOnr8bY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset with shape feature extraction\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    areas = []\n",
        "    perimeters = []\n",
        "    circularities = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                # Shape feature extraction\n",
        "                contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                area = 0\n",
        "                perimeter = 0\n",
        "                circularity = 0\n",
        "\n",
        "                if contours:\n",
        "                    contour = contours[0]\n",
        "                    area = cv2.contourArea(contour)\n",
        "                    perimeter = cv2.arcLength(contour, True)\n",
        "                    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "                # Append shape features to the respective lists\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                areas.append(area)\n",
        "                perimeters.append(perimeter)\n",
        "                circularities.append(circularity)\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(areas), np.array(perimeters), np.array(circularities)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels, areas, perimeters, circularities = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Calculate the overall mean values for area, perimeter, and circularity\n",
        "overall_mean_area = np.mean(areas)\n",
        "overall_mean_perimeter = np.mean(perimeters)\n",
        "overall_mean_circularity = np.mean(circularities)\n",
        "\n",
        "print(\"Overall Mean Area:\", overall_mean_area)\n",
        "print(\"Overall Mean Perimeter:\", overall_mean_perimeter)\n",
        "print(\"Overall Mean Circularity:\", overall_mean_circularity)\n",
        "\n",
        "# Combine shape features with flattened image pixels\n",
        "combined_features = np.column_stack((images.reshape(len(images), -1), areas, perimeters, circularities))\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hnC_ITT0SnZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLuGlG60pg8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVuvDJqN0pzW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf curl\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cjee1odT044F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqQfpvS005Nm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMpaSxhJ1Ix_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb7mjUGn1JFh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN1pOqHQ1VyC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJUIiDNR1WEf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPHnnGxO26el"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwmZjDUg3Dlh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf curl\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx1EXtbO3JKQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78SWW4-R3SPe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKjGGOvb3jFX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z8IA_cz40Ck"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qK_zy3n48fg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf curl\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2COll-75DSC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmGXxfP05KcI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRO-Mxhe5iT6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGnpE_ejaewc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "config = ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5FJKf7paU3Q"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuX6p56HaYi2"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/healthy/train'\n",
        "valid_path = '/healthy/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFpg8tQ3bEnu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "# Define input shape and load InceptionV3 with pre-trained weights\n",
        "IMAGE_SIZE = (224, 224)\n",
        "inception = InceptionV3(input_shape=IMAGE_SIZE + (3,), weights='imagenet', include_top=False)\n",
        "\n",
        "# Now you can use the 'inception' model for your tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAzipqPFbr00"
      },
      "outputs": [],
      "source": [
        "for layer in inception.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJIOThZcb3QU"
      },
      "outputs": [],
      "source": [
        "folders = glob('/healthy/train/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Buz6ypzUb6m7"
      },
      "outputs": [],
      "source": [
        "x = Flatten()(inception.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ3HWKDQb9v6"
      },
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=inception.input, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFpwvcMsb_GB"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeZrQy5McE4z"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XbJwmRkeZAO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NefFz6lqecCD"
      },
      "outputs": [],
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/healthy',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phwtj9ZLgUAd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LMYGsSds7rHI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function for Attention-based SE mechanism\n",
        "def squeeze_excite_block(input_tensor, ratio=16):\n",
        "    channels = input_tensor.shape[-1]\n",
        "\n",
        "    # Global Average Pooling\n",
        "    squeeze = GlobalAveragePooling2D()(input_tensor)\n",
        "\n",
        "    # Excitation\n",
        "    excitation = Dense(channels // ratio, activation='relu')(squeeze)\n",
        "    excitation = Dense(channels, activation='sigmoid')(excitation)\n",
        "\n",
        "    # Reshape to match the input shape\n",
        "    excitation = Reshape((1, 1, channels))(excitation)\n",
        "\n",
        "    # Scale input\n",
        "    scaled_input = Multiply()([input_tensor, excitation])\n",
        "\n",
        "    return scaled_input\n",
        "\n",
        "# Load pre-trained ResNet50 model with Squeeze-and-Excitation\n",
        "def create_base_model(input_shape):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze the base model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return base_model\n",
        "\n",
        "# Function to perform detection without loading the model\n",
        "def detect_chili_disease(segmented_image, input_shape=(224, 224, 3), num_classes=5):\n",
        "    # Create the base model\n",
        "    base_model = create_base_model(input_shape)\n",
        "\n",
        "    # Additional layers for classification\n",
        "    attention_se = squeeze_excite_block(base_model.output)\n",
        "\n",
        "    # Apply Global Average Pooling to segmented_image\n",
        "    segmentation_pooled = GlobalAveragePooling2D()(segmented_image)\n",
        "\n",
        "    # Reshape segmentation_pooled to match base_model.output shape\n",
        "    segmentation_reshaped = Reshape((1, 1, segmentation_pooled.shape[-1]))(segmentation_pooled)\n",
        "\n",
        "    # Repeat segmentation_reshaped along the spatial dimensions\n",
        "    segmentation_repeated = tf.tile(segmentation_reshaped, (1, base_model.output_shape[1], base_model.output_shape[2], 1))\n",
        "\n",
        "    # Concatenate the features\n",
        "    concatenated_features = Concatenate()([base_model.output, attention_se, segmentation_repeated])\n",
        "\n",
        "    # Classification head\n",
        "    global_average_pooling = GlobalAveragePooling2D()(concatenated_features)\n",
        "    dense1 = Dense(128, activation='relu')(global_average_pooling)\n",
        "    output = Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "    # Create the final model with segmentation input and classification output\n",
        "    model = tf.keras.models.Model(inputs=[base_model.input], outputs=output)\n",
        "\n",
        "    # Assuming you have the label names for mapping\n",
        "    class_names = [\"Healthy\", \"Leaf curl\", \"Leaf spot\", \"whitefly\", \"yellowish\"]\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict([segmented_image])\n",
        "    predicted_class = np.argmax(predictions)\n",
        "\n",
        "    return class_names[predicted_class]\n",
        "\n",
        "# Assuming your input images are 224x224 with 3 channels (adjust according to your actual data)\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Number of classes in your classification problem\n",
        "num_classes = 5  # Modify based on your dataset\n",
        "\n",
        "# Load the segmented image (replace with your actual image path)\n",
        "segmented_image_path = \"/content/drive/MyDrive/segmented data/whitefly4.jpg\"\n",
        "segmented_image = cv2.imread(segmented_image_path)\n",
        "segmented_image = cv2.resize(segmented_image, (224, 224))\n",
        "segmented_image = np.expand_dims(segmented_image, axis=0).astype(np.float32)  # Ensure float32 dtype\n",
        "\n",
        "# Perform detection without loading the model\n",
        "predicted_class = detect_chili_disease(segmented_image, input_shape, num_classes)\n",
        "\n",
        "# Display the segmented image and prediction\n",
        "plt.imshow(cv2.cvtColor(segmented_image.squeeze().astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"Predicted Class: {predicted_class}\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvIhYrom4whv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7I5155BPwcPd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 1)\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Convolutional Layers for image\n",
        "conv1_image = layers.Conv2D(64, (3, 3), padding='same')(input_layer_image)\n",
        "conv1_image = layers.BatchNormalization()(conv1_image)\n",
        "conv1_image = layers.Activation('relu')(conv1_image)\n",
        "pool1_image = layers.MaxPooling2D()(conv1_image)\n",
        "\n",
        "conv2_image = layers.Conv2D(128, (5, 5), padding='same')(pool1_image)\n",
        "conv2_image = layers.BatchNormalization()(conv2_image)\n",
        "conv2_image = layers.Activation('relu')(conv2_image)\n",
        "pool2_image = layers.MaxPooling2D()(conv2_image)\n",
        "\n",
        "conv3_image = layers.Conv2D(256, (7, 7), padding='same')(pool2_image)\n",
        "conv3_image = layers.BatchNormalization()(conv3_image)\n",
        "conv3_image = layers.Activation('relu')(conv3_image)\n",
        "pool3_image = layers.MaxPooling2D()(conv3_image)\n",
        "\n",
        "# Convolutional Layers for segmented chili\n",
        "conv1_chili = layers.Conv2D(32, (3, 3), padding='same')(input_layer_segmented_chili)\n",
        "conv1_chili = layers.BatchNormalization()(conv1_chili)\n",
        "conv1_chili = layers.Activation('relu')(conv1_chili)\n",
        "pool1_chili = layers.MaxPooling2D()(conv1_chili)\n",
        "\n",
        "conv2_chili = layers.Conv2D(64, (5, 5), padding='same')(pool1_chili)\n",
        "conv2_chili = layers.BatchNormalization()(conv2_chili)\n",
        "conv2_chili = layers.Activation('relu')(conv2_chili)\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(2, 2))(conv2_chili)\n",
        "\n",
        "# Crop chili features to have the same spatial dimensions as image features\n",
        "crop_size = int((up_sampled_chili.shape[1] - pool3_image.shape[1]) // 2)\n",
        "up_sampled_chili = layers.Cropping2D(cropping=((crop_size, crop_size), (crop_size, crop_size)))(up_sampled_chili)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([pool3_image, up_sampled_chili])\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(pool4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator\n",
        "# Load your segmented chili images using ImageDataGenerator\n",
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen_chili = ImageDataGenerator(rescale=1./255)  # Remove the color_mode parameter\n",
        "train_generator_segmented_chili = data_gen_chili.flow_from_directory(\n",
        "    '/content/drive/MyDrive/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    color_mode='grayscale'  # Add color_mode='grayscale' for chili images\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label)\n",
        "\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/classification/mdsg_se_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQu8OL9iEd6Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyj12pw08h6O"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Convolutional Layers for image\n",
        "conv1_image = layers.Conv2D(64, (3, 3), padding='same')(input_layer_image)\n",
        "conv1_image = layers.BatchNormalization()(conv1_image)\n",
        "conv1_image = layers.Activation('relu')(conv1_image)\n",
        "pool1_image = layers.MaxPooling2D()(conv1_image)\n",
        "\n",
        "conv2_image = layers.Conv2D(128, (5, 5), padding='same')(pool1_image)\n",
        "conv2_image = layers.BatchNormalization()(conv2_image)\n",
        "conv2_image = layers.Activation('relu')(conv2_image)\n",
        "pool2_image = layers.MaxPooling2D()(conv2_image)\n",
        "\n",
        "conv3_image = layers.Conv2D(256, (7, 7), padding='same')(pool2_image)\n",
        "conv3_image = layers.BatchNormalization()(conv3_image)\n",
        "conv3_image = layers.Activation('relu')(conv3_image)\n",
        "pool3_image = layers.MaxPooling2D()(conv3_image)\n",
        "\n",
        "# Convolutional Layers for segmented chili\n",
        "conv1_chili = layers.Conv2D(32, (3, 3), padding='same')(input_layer_segmented_chili)\n",
        "conv1_chili = layers.BatchNormalization()(conv1_chili)\n",
        "conv1_chili = layers.Activation('relu')(conv1_chili)\n",
        "pool1_chili = layers.MaxPooling2D()(conv1_chili)\n",
        "\n",
        "conv2_chili = layers.Conv2D(64, (5, 5), padding='same')(pool1_chili)\n",
        "conv2_chili = layers.BatchNormalization()(conv2_chili)\n",
        "conv2_chili = layers.Activation('relu')(conv2_chili)\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(2, 2))(conv2_chili)\n",
        "\n",
        "# Crop chili features to have the same spatial dimensions as image features\n",
        "crop_size = int((up_sampled_chili.shape[1] - pool3_image.shape[1]) // 2)\n",
        "up_sampled_chili = layers.Cropping2D(cropping=((crop_size, crop_size), (crop_size, crop_size)))(up_sampled_chili)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([pool3_image, up_sampled_chili])\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(pool4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Print debug information\n",
        "        print(f\"Batch Image Shape: {batch_image.shape}\")\n",
        "        print(f\"Batch Chili Shape: {batch_chili.shape}\")\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        # You may need to adapt this depending on the structure of your model\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms-Sg8il7BYb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kcSbmAcu7Mmr"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Convolutional Layers for image\n",
        "conv1_image = layers.Conv2D(64, (3, 3), padding='same')(input_layer_image)\n",
        "conv1_image = layers.BatchNormalization()(conv1_image)\n",
        "conv1_image = layers.Activation('relu')(conv1_image)\n",
        "pool1_image = layers.MaxPooling2D()(conv1_image)\n",
        "\n",
        "conv2_image = layers.Conv2D(128, (5, 5), padding='same')(pool1_image)\n",
        "conv2_image = layers.BatchNormalization()(conv2_image)\n",
        "conv2_image = layers.Activation('relu')(conv2_image)\n",
        "pool2_image = layers.MaxPooling2D()(conv2_image)\n",
        "\n",
        "conv3_image = layers.Conv2D(256, (7, 7), padding='same')(pool2_image)\n",
        "conv3_image = layers.BatchNormalization()(conv3_image)\n",
        "conv3_image = layers.Activation('relu')(conv3_image)\n",
        "pool3_image = layers.MaxPooling2D()(conv3_image)\n",
        "\n",
        "# Convolutional Layers for segmented chili\n",
        "conv1_chili = layers.Conv2D(32, (3, 3), padding='same')(input_layer_segmented_chili)\n",
        "conv1_chili = layers.BatchNormalization()(conv1_chili)\n",
        "conv1_chili = layers.Activation('relu')(conv1_chili)\n",
        "pool1_chili = layers.MaxPooling2D()(conv1_chili)\n",
        "\n",
        "conv2_chili = layers.Conv2D(64, (5, 5), padding='same')(pool1_chili)\n",
        "conv2_chili = layers.BatchNormalization()(conv2_chili)\n",
        "conv2_chili = layers.Activation('relu')(conv2_chili)\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(2, 2))(conv2_chili)\n",
        "\n",
        "# Crop chili features to have the same spatial dimensions as image features\n",
        "crop_size = int((up_sampled_chili.shape[1] - pool3_image.shape[1]) // 2)\n",
        "up_sampled_chili = layers.Cropping2D(cropping=((crop_size, crop_size), (crop_size, crop_size)))(up_sampled_chili)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([pool3_image, up_sampled_chili])\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(pool4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Print debug information\n",
        "        print(f\"Batch Image Shape: {batch_image.shape}\")\n",
        "        print(f\"Batch Chili Shape: {batch_chili.shape}\")\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        # You may need to adapt this depending on the structure of your model\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "# Save the trained model\n",
        "loaded_model = keras.models.load_model('my_model.keras')\n",
        "loaded_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSNYK9n6ZQ8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample code for loading images and labels (modify according to your dataset structure)\n",
        "def load_data(img_folder, img_height, img_width):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(img_folder):\n",
        "        img = load_img(os.path.join(img_folder, filename), target_size=(img_height, img_width))\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "        # Extract the label from the filename or use a predefined mapping\n",
        "        labels.append(extract_label_from_filename(filename))  # Implement a function to extract the label\n",
        "    return images, labels\n",
        "\n",
        "def extract_label_from_filename(filename):\n",
        "    # Implement your logic to extract the label from the filename\n",
        "    # For example, if filenames are like 'Healthy1.jpg' or 'Diseased2.jpg'\n",
        "    return filename.split('.')[0].lower()\n",
        "\n",
        "# Define the dimensions of your input images\n",
        "img_height, img_width, img_channels = 128, 128, 3  # Adjust these values based on your dataset\n",
        "\n",
        "img_folder = '/content/drive/MyDrive/segmentation/yellowish'\n",
        "images, labels = load_data(img_folder, img_height, img_width)\n",
        "\n",
        "# Convert labels to numerical format\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = len(np.unique(labels))\n",
        "\n",
        "# Preprocess and split the data\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model with dynamic channel gating\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, img_channels)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Dynamic channel gating layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten the model and add dense layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Image data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255  # Add normalization\n",
        ")\n",
        "\n",
        "# Train the model with data augmentation\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=len(X_train) / batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot training history (accuracy and loss in one graph)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.title('Training History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hED9EAKTfReC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 128, 128, 3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# Load segmented images and labels\n",
        "def load_data(img_folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(img_folder):\n",
        "        img = load_img(os.path.join(img_folder, filename), target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "        label = extract_label_from_filename(filename)\n",
        "        labels.append(label)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "def extract_label_from_filename(filename):\n",
        "    return filename.split('.')[0].lower()\n",
        "\n",
        "# Load your segmented images and labels\n",
        "img_folder = '/content/drive/MyDrive/classification/segmentation/yellowish'\n",
        "images, labels = load_data(img_folder)\n",
        "\n",
        "# Convert labels to numerical format\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "# Preprocess and split the data\n",
        "X = np.array(images) / 255.0  # Normalize pixel values to [0, 1]\n",
        "y = to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Multi-scale SE block as a custom layer\n",
        "class SEBlock(layers.Layer):\n",
        "    def __init__(self, ratio=8, **kwargs):\n",
        "        super(SEBlock, self).__init__(**kwargs)\n",
        "        self.ratio = ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        num_channels = input_shape[-1]\n",
        "        self.bottleneck = num_channels // self.ratio\n",
        "\n",
        "        self.squeeze = layers.GlobalAveragePooling2D()\n",
        "        self.excitation = tf.keras.Sequential([\n",
        "            layers.Conv2D(self.bottleneck, (1, 1), activation='relu'),\n",
        "            layers.Conv2D(num_channels, (1, 1), activation='sigmoid')\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        x_squeeze = self.squeeze(x)\n",
        "        x_excitation = self.excitation(tf.expand_dims(tf.expand_dims(x_squeeze, axis=1), axis=1))\n",
        "        x_scaled = tf.multiply(x, x_excitation)\n",
        "        return x_scaled\n",
        "\n",
        "# Build the model with Multi-scale SE blocks\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(SEBlock())\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(SEBlock())\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(SEBlock())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
        "\n",
        "# Plot training history (accuracy and loss in one graph)\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dr3wRqli_-x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxwNEaY9l9zO"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Convolutional Layers for image\n",
        "conv1_image = layers.Conv2D(64, (3, 3), padding='same')(input_layer_image)\n",
        "conv1_image = layers.BatchNormalization()(conv1_image)\n",
        "conv1_image = layers.Activation('relu')(conv1_image)\n",
        "pool1_image = layers.MaxPooling2D()(conv1_image)\n",
        "\n",
        "conv2_image = layers.Conv2D(128, (5, 5), padding='same')(pool1_image)\n",
        "conv2_image = layers.BatchNormalization()(conv2_image)\n",
        "conv2_image = layers.Activation('relu')(conv2_image)\n",
        "pool2_image = layers.MaxPooling2D()(conv2_image)\n",
        "\n",
        "conv3_image = layers.Conv2D(256, (7, 7), padding='same')(pool2_image)\n",
        "conv3_image = layers.BatchNormalization()(conv3_image)\n",
        "conv3_image = layers.Activation('relu')(conv3_image)\n",
        "pool3_image = layers.MaxPooling2D()(conv3_image)\n",
        "\n",
        "# Convolutional Layers for segmented chili\n",
        "conv1_chili = layers.Conv2D(32, (3, 3), padding='same')(input_layer_segmented_chili)\n",
        "conv1_chili = layers.BatchNormalization()(conv1_chili)\n",
        "conv1_chili = layers.Activation('relu')(conv1_chili)\n",
        "pool1_chili = layers.MaxPooling2D()(conv1_chili)\n",
        "\n",
        "conv2_chili = layers.Conv2D(64, (5, 5), padding='same')(pool1_chili)\n",
        "conv2_chili = layers.BatchNormalization()(conv2_chili)\n",
        "conv2_chili = layers.Activation('relu')(conv2_chili)\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(2, 2))(conv2_chili)\n",
        "\n",
        "# Crop chili features to have the same spatial dimensions as image features\n",
        "crop_size = int((up_sampled_chili.shape[1] - pool3_image.shape[1]) // 2)\n",
        "up_sampled_chili = layers.Cropping2D(cropping=((crop_size, crop_size), (crop_size, crop_size)))(up_sampled_chili)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([pool3_image, up_sampled_chili])\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(pool4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIX9IoeKt7pa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngD9QQ0huCEE"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Convolutional Layers for image\n",
        "conv1_image = layers.Conv2D(64, (3, 3), padding='same')(input_layer_image)\n",
        "conv1_image = layers.BatchNormalization()(conv1_image)\n",
        "conv1_image = layers.Activation('relu')(conv1_image)\n",
        "pool1_image = layers.MaxPooling2D()(conv1_image)\n",
        "\n",
        "conv2_image = layers.Conv2D(128, (5, 5), padding='same')(pool1_image)\n",
        "conv2_image = layers.BatchNormalization()(conv2_image)\n",
        "conv2_image = layers.Activation('relu')(conv2_image)\n",
        "pool2_image = layers.MaxPooling2D()(conv2_image)\n",
        "\n",
        "conv3_image = layers.Conv2D(256, (7, 7), padding='same')(pool2_image)\n",
        "conv3_image = layers.BatchNormalization()(conv3_image)\n",
        "conv3_image = layers.Activation('relu')(conv3_image)\n",
        "pool3_image = layers.MaxPooling2D()(conv3_image)\n",
        "\n",
        "# Convolutional Layers for segmented chili\n",
        "conv1_chili = layers.Conv2D(32, (3, 3), padding='same')(input_layer_segmented_chili)\n",
        "conv1_chili = layers.BatchNormalization()(conv1_chili)\n",
        "conv1_chili = layers.Activation('relu')(conv1_chili)\n",
        "pool1_chili = layers.MaxPooling2D()(conv1_chili)\n",
        "\n",
        "conv2_chili = layers.Conv2D(64, (5, 5), padding='same')(pool1_chili)\n",
        "conv2_chili = layers.BatchNormalization()(conv2_chili)\n",
        "conv2_chili = layers.Activation('relu')(conv2_chili)\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(2, 2))(conv2_chili)\n",
        "\n",
        "# Crop chili features to have the same spatial dimensions as image features\n",
        "crop_size = int((up_sampled_chili.shape[1] - pool3_image.shape[1]) // 2)\n",
        "up_sampled_chili = layers.Cropping2D(cropping=((crop_size, crop_size), (crop_size, crop_size)))(up_sampled_chili)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([pool3_image, up_sampled_chili])\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(pool4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVxTQLkk0c3K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFIcJlfq0dZg"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Convolutional Layers for image\n",
        "conv1_image = layers.Conv2D(64, (3, 3), padding='same')(input_layer_image)\n",
        "conv1_image = layers.BatchNormalization()(conv1_image)\n",
        "conv1_image = layers.Activation('relu')(conv1_image)\n",
        "pool1_image = layers.MaxPooling2D()(conv1_image)\n",
        "\n",
        "conv2_image = layers.Conv2D(128, (5, 5), padding='same')(pool1_image)\n",
        "conv2_image = layers.BatchNormalization()(conv2_image)\n",
        "conv2_image = layers.Activation('relu')(conv2_image)\n",
        "pool2_image = layers.MaxPooling2D()(conv2_image)\n",
        "\n",
        "conv3_image = layers.Conv2D(256, (7, 7), padding='same')(pool2_image)\n",
        "conv3_image = layers.BatchNormalization()(conv3_image)\n",
        "conv3_image = layers.Activation('relu')(conv3_image)\n",
        "pool3_image = layers.MaxPooling2D()(conv3_image)\n",
        "\n",
        "# Convolutional Layers for segmented chili\n",
        "conv1_chili = layers.Conv2D(32, (3, 3), padding='same')(input_layer_segmented_chili)\n",
        "conv1_chili = layers.BatchNormalization()(conv1_chili)\n",
        "conv1_chili = layers.Activation('relu')(conv1_chili)\n",
        "pool1_chili = layers.MaxPooling2D()(conv1_chili)\n",
        "\n",
        "conv2_chili = layers.Conv2D(64, (5, 5), padding='same')(pool1_chili)\n",
        "conv2_chili = layers.BatchNormalization()(conv2_chili)\n",
        "conv2_chili = layers.Activation('relu')(conv2_chili)\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(2, 2))(conv2_chili)\n",
        "\n",
        "# Crop chili features to have the same spatial dimensions as image features\n",
        "crop_size = int((up_sampled_chili.shape[1] - pool3_image.shape[1]) // 2)\n",
        "up_sampled_chili = layers.Cropping2D(cropping=((crop_size, crop_size), (crop_size, crop_size)))(up_sampled_chili)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([pool3_image, up_sampled_chili])\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(pool4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOiyQpk8XYR4"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Convolutional Layers for image\n",
        "conv1_image = layers.Conv2D(64, (3, 3), padding='same')(input_layer_image)\n",
        "conv1_image = layers.BatchNormalization()(conv1_image)\n",
        "conv1_image = layers.Activation('relu')(conv1_image)\n",
        "pool1_image = layers.MaxPooling2D()(conv1_image)\n",
        "\n",
        "conv2_image = layers.Conv2D(128, (5, 5), padding='same')(pool1_image)\n",
        "conv2_image = layers.BatchNormalization()(conv2_image)\n",
        "conv2_image = layers.Activation('relu')(conv2_image)\n",
        "pool2_image = layers.MaxPooling2D()(conv2_image)\n",
        "\n",
        "conv3_image = layers.Conv2D(256, (7, 7), padding='same')(pool2_image)\n",
        "conv3_image = layers.BatchNormalization()(conv3_image)\n",
        "conv3_image = layers.Activation('relu')(conv3_image)\n",
        "pool3_image = layers.MaxPooling2D()(conv3_image)\n",
        "\n",
        "# Convolutional Layers for segmented chili\n",
        "conv1_chili = layers.Conv2D(32, (3, 3), padding='same')(input_layer_segmented_chili)\n",
        "conv1_chili = layers.BatchNormalization()(conv1_chili)\n",
        "conv1_chili = layers.Activation('relu')(conv1_chili)\n",
        "pool1_chili = layers.MaxPooling2D()(conv1_chili)\n",
        "\n",
        "conv2_chili = layers.Conv2D(64, (5, 5), padding='same')(pool1_chili)\n",
        "conv2_chili = layers.BatchNormalization()(conv2_chili)\n",
        "conv2_chili = layers.Activation('relu')(conv2_chili)\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(2, 2))(conv2_chili)\n",
        "\n",
        "# Crop chili features to have the same spatial dimensions as image features\n",
        "crop_size = int((up_sampled_chili.shape[1] - pool3_image.shape[1]) // 2)\n",
        "up_sampled_chili = layers.Cropping2D(cropping=((crop_size, crop_size), (crop_size, crop_size)))(up_sampled_chili)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([pool3_image, up_sampled_chili])\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(pool4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 200\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgG_WIeFxC39"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Function to create Shufflenet v1 block\n",
        "def shufflenet_block(x, groups=1, name=None):\n",
        "    channel_axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
        "    in_channels = x.shape[channel_axis]\n",
        "    x = layers.Conv2D(in_channels, (1, 1), groups=groups, activation='relu', name=name + '_gconv_1x1')(x)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False, name=name + '_dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_dwconv_bn')(x)\n",
        "    x = layers.Conv2D(in_channels, (1, 1), activation='relu', name=name + '_pwconv_1x1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_pwconv_bn')(x)\n",
        "    return x\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Use MobileNetV2 as the base model for image features\n",
        "base_model_image = MobileNetV2(input_shape=input_shape_image, include_top=False, weights='imagenet')\n",
        "base_model_image.trainable = False  # Freeze base model weights\n",
        "image_features = base_model_image(input_layer_image)\n",
        "\n",
        "# Shufflenet block for segmented chili\n",
        "shufflenet_block_chili = shufflenet_block(input_layer_segmented_chili, groups=3, name='shufflenet_chili')\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(7, 7))(shufflenet_block_chili)\n",
        "\n",
        "# Apply global average pooling to up_sampled_chili\n",
        "up_sampled_chili_pooled = layers.GlobalAveragePooling2D()(up_sampled_chili)\n",
        "\n",
        "# Apply global average pooling to image_features\n",
        "image_features_pooled = layers.GlobalAveragePooling2D()(image_features)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([image_features_pooled, up_sampled_chili_pooled])\n",
        "print(\"Shape of merged_features before reshaping:\", merged_features.shape)\n",
        "\n",
        "# Reshape merged_features to have a proper shape\n",
        "merged_features_reshaped = layers.Reshape((1, 1, 1283))(merged_features)\n",
        "print(\"Shape of merged_features after reshaping:\", merged_features_reshaped.shape)\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features_reshaped, 256)\n",
        "\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "\n",
        "# Remove MaxPooling2D or adjust pool size if needed\n",
        "# pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(conv4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2oVatGC8aPC"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Function to create Shufflenet v1 block\n",
        "def shufflenet_block(x, groups=1, name=None):\n",
        "    channel_axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
        "    in_channels = x.shape[channel_axis]\n",
        "    x = layers.Conv2D(in_channels, (1, 1), groups=groups, activation='relu', name=name + '_gconv_1x1')(x)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False, name=name + '_dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_dwconv_bn')(x)\n",
        "    x = layers.Conv2D(in_channels, (1, 1), activation='relu', name=name + '_pwconv_1x1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_pwconv_bn')(x)\n",
        "    return x\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Use MobileNetV2 as the base model for image features\n",
        "base_model_image = MobileNetV2(input_shape=input_shape_image, include_top=False, weights='imagenet')\n",
        "base_model_image.trainable = False  # Freeze base model weights\n",
        "image_features = base_model_image(input_layer_image)\n",
        "\n",
        "# Shufflenet block for segmented chili\n",
        "shufflenet_block_chili = shufflenet_block(input_layer_segmented_chili, groups=3, name='shufflenet_chili')\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(7, 7))(shufflenet_block_chili)\n",
        "\n",
        "# Apply global average pooling to up_sampled_chili\n",
        "up_sampled_chili_pooled = layers.GlobalAveragePooling2D()(up_sampled_chili)\n",
        "\n",
        "# Apply global average pooling to image_features\n",
        "image_features_pooled = layers.GlobalAveragePooling2D()(image_features)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([image_features_pooled, up_sampled_chili_pooled])\n",
        "print(\"Shape of merged_features before reshaping:\", merged_features.shape)\n",
        "\n",
        "# Reshape merged_features to have a proper shape\n",
        "merged_features_reshaped = layers.Reshape((1, 1, 1283))(merged_features)\n",
        "print(\"Shape of merged_features after reshaping:\", merged_features_reshaped.shape)\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features_reshaped, 256)\n",
        "\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "\n",
        "# Remove MaxPooling2D or adjust pool size if needed\n",
        "# pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(conv4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fuq-UQFV-DKQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Function to create Shufflenet v1 block\n",
        "def shufflenet_block(x, groups=1, name=None):\n",
        "    channel_axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
        "    in_channels = x.shape[channel_axis]\n",
        "    x = layers.Conv2D(in_channels, (1, 1), groups=groups, activation='relu', name=name + '_gconv_1x1')(x)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False, name=name + '_dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_dwconv_bn')(x)\n",
        "    x = layers.Conv2D(in_channels, (1, 1), activation='relu', name=name + '_pwconv_1x1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_pwconv_bn')(x)\n",
        "    return x\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Use MobileNetV2 as the base model for image features\n",
        "base_model_image = MobileNetV2(input_shape=input_shape_image, include_top=False, weights='imagenet')\n",
        "base_model_image.trainable = False  # Freeze base model weights\n",
        "image_features = base_model_image(input_layer_image)\n",
        "\n",
        "# Shufflenet block for segmented chili\n",
        "shufflenet_block_chili = shufflenet_block(input_layer_segmented_chili, groups=3, name='shufflenet_chili')\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(7, 7))(shufflenet_block_chili)\n",
        "\n",
        "# Apply global average pooling to up_sampled_chili\n",
        "up_sampled_chili_pooled = layers.GlobalAveragePooling2D()(up_sampled_chili)\n",
        "\n",
        "# Apply global average pooling to image_features\n",
        "image_features_pooled = layers.GlobalAveragePooling2D()(image_features)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([image_features_pooled, up_sampled_chili_pooled])\n",
        "print(\"Shape of merged_features before reshaping:\", merged_features.shape)\n",
        "\n",
        "# Reshape merged_features to have a proper shape\n",
        "merged_features_reshaped = layers.Reshape((1, 1, 1283))(merged_features)\n",
        "print(\"Shape of merged_features after reshaping:\", merged_features_reshaped.shape)\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features_reshaped, 256)\n",
        "\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "\n",
        "# Remove MaxPooling2D or adjust pool size if needed\n",
        "# pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(conv4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zay37jykC-4P"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Function to create Shufflenet v1 block\n",
        "def shufflenet_block(x, groups=1, name=None):\n",
        "    channel_axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
        "    in_channels = x.shape[channel_axis]\n",
        "    x = layers.Conv2D(in_channels, (1, 1), groups=groups, activation='relu', name=name + '_gconv_1x1')(x)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False, name=name + '_dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_dwconv_bn')(x)\n",
        "    x = layers.Conv2D(in_channels, (1, 1), activation='relu', name=name + '_pwconv_1x1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_pwconv_bn')(x)\n",
        "    return x\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Use MobileNetV2 as the base model for image features\n",
        "base_model_image = MobileNetV2(input_shape=input_shape_image, include_top=False, weights='imagenet')\n",
        "base_model_image.trainable = False  # Freeze base model weights\n",
        "image_features = base_model_image(input_layer_image)\n",
        "\n",
        "# Shufflenet block for segmented chili\n",
        "shufflenet_block_chili = shufflenet_block(input_layer_segmented_chili, groups=3, name='shufflenet_chili')\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(7, 7))(shufflenet_block_chili)\n",
        "\n",
        "# Apply global average pooling to up_sampled_chili\n",
        "up_sampled_chili_pooled = layers.GlobalAveragePooling2D()(up_sampled_chili)\n",
        "\n",
        "# Apply global average pooling to image_features\n",
        "image_features_pooled = layers.GlobalAveragePooling2D()(image_features)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([image_features_pooled, up_sampled_chili_pooled])\n",
        "print(\"Shape of merged_features before reshaping:\", merged_features.shape)\n",
        "\n",
        "# Reshape merged_features to have a proper shape\n",
        "merged_features_reshaped = layers.Reshape((1, 1, 1283))(merged_features)\n",
        "print(\"Shape of merged_features after reshaping:\", merged_features_reshaped.shape)\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features_reshaped, 256)\n",
        "\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "\n",
        "# Remove MaxPooling2D or adjust pool size if needed\n",
        "# pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(conv4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLyK2de9zhNs"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Function to create Shufflenet v1 block\n",
        "def shufflenet_block(x, groups=1, name=None):\n",
        "    channel_axis = 1 if keras.backend.image_data_format() == 'channels_first' else -1\n",
        "    in_channels = x.shape[channel_axis]\n",
        "    x = layers.Conv2D(in_channels, (1, 1), groups=groups, activation='relu', name=name + '_gconv_1x1')(x)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False, name=name + '_dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_dwconv_bn')(x)\n",
        "    x = layers.Conv2D(in_channels, (1, 1), activation='relu', name=name + '_pwconv_1x1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_pwconv_bn')(x)\n",
        "    return x\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Use MobileNetV2 as the base model for image features\n",
        "base_model_image = MobileNetV2(input_shape=input_shape_image, include_top=False, weights='imagenet')\n",
        "base_model_image.trainable = False  # Freeze base model weights\n",
        "image_features = base_model_image(input_layer_image)\n",
        "\n",
        "# Shufflenet block for segmented chili\n",
        "shufflenet_block_chili = shufflenet_block(input_layer_segmented_chili, groups=3, name='shufflenet_chili')\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(7, 7))(shufflenet_block_chili)\n",
        "\n",
        "# Apply global average pooling to up_sampled_chili\n",
        "up_sampled_chili_pooled = layers.GlobalAveragePooling2D()(up_sampled_chili)\n",
        "\n",
        "# Apply global average pooling to image_features\n",
        "image_features_pooled = layers.GlobalAveragePooling2D()(image_features)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([image_features_pooled, up_sampled_chili_pooled])\n",
        "print(\"Shape of merged_features before reshaping:\", merged_features.shape)\n",
        "\n",
        "# Reshape merged_features to have a proper shape\n",
        "merged_features_reshaped = layers.Reshape((1, 1, 1283))(merged_features)\n",
        "print(\"Shape of merged_features after reshaping:\", merged_features_reshaped.shape)\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features_reshaped, 256)\n",
        "\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "\n",
        "# Remove MaxPooling2D or adjust pool size if needed\n",
        "# pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(conv4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 200\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuJZgc5tUvBg"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def shufflenet_block(x, groups=1, name=None):\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "    in_channels = x.shape[channel_axis]\n",
        "\n",
        "    # Ensure that the number of input channels is divisible by the number of groups\n",
        "    if in_channels % groups != 0:\n",
        "        groups = in_channels  # Set groups to in_channels if not divisible\n",
        "\n",
        "    # Ensure that the number of filters is divisible by the number of groups\n",
        "    filters = in_channels // groups\n",
        "    filters = max(filters, groups)  # Set filters to groups if it becomes zero\n",
        "\n",
        "    # ShuffleNet block\n",
        "    x = layers.Conv2D(filters, (1, 1), groups=groups, activation='relu', name=name + '_gconv_1x1')(x)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False, name=name + '_dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_dwconv_bn')(x)\n",
        "    x = layers.Conv2D(filters, (1, 1), activation='relu', name=name + '_pwconv_1x1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_pwconv_bn')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Build the model\n",
        "input_shape_image = (224, 224, 3)\n",
        "input_shape_segmented_chili = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "input_layer_segmented_chili = layers.Input(shape=input_shape_segmented_chili, name='segmented_chili_input')\n",
        "\n",
        "# Use MobileNetV2 as the base model for image features\n",
        "base_model_image = MobileNetV2(input_shape=input_shape_image, include_top=False, weights='imagenet')\n",
        "base_model_image.trainable = False  # Freeze base model weights\n",
        "image_features = base_model_image(input_layer_image)\n",
        "\n",
        "# Shufflenet block for image features\n",
        "shufflenet_block_image = shufflenet_block(image_features, groups=3, name='shufflenet_image')\n",
        "\n",
        "# Upsample chili features to match the shape of image features\n",
        "up_sampled_chili = layers.UpSampling2D(size=(7, 7))(shufflenet_block_image)\n",
        "\n",
        "# Apply global average pooling to up_sampled_chili\n",
        "up_sampled_chili_pooled = layers.GlobalAveragePooling2D()(up_sampled_chili)\n",
        "\n",
        "# Apply global average pooling to image_features\n",
        "image_features_pooled = layers.GlobalAveragePooling2D()(image_features)\n",
        "\n",
        "# Concatenate image and chili features\n",
        "merged_features = layers.Concatenate()([image_features_pooled, up_sampled_chili_pooled])\n",
        "print(\"Shape of merged_features before reshaping:\", merged_features.shape)\n",
        "\n",
        "# Reshape merged_features to have a proper shape\n",
        "# Assuming merged_features has a shape of (None, 2560)\n",
        "merged_features_reshaped = layers.Reshape((4, 4, 160))(merged_features)\n",
        "\n",
        "print(\"Shape of merged_features after reshaping:\", merged_features_reshaped.shape)\n",
        "\n",
        "# MDSG-SE block\n",
        "mdsg_se = mdsg_se_block(merged_features_reshaped, 256)\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(mdsg_se)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "\n",
        "# Remove MaxPooling2D or adjust pool size if needed\n",
        "# pool4 = layers.MaxPooling2D()(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(conv4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = keras.Model(inputs=[input_layer_image, input_layer_segmented_chili], outputs=output_layer)\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your segmented chili images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1./255)  # No data augmentation for validation\n",
        "\n",
        "def grayscale_image_generator(generator):\n",
        "    for batch in generator:\n",
        "        batch_images, batch_labels = batch\n",
        "        grayscale_images = np.array([np.array(Image.fromarray(img).convert(\"L\")) for img in batch_images])\n",
        "        yield (grayscale_images, batch_labels)\n",
        "\n",
        "train_generator_segmented_chili = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/segmentation',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "        batch_chili, _ = train_generator_segmented_chili.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Ensure model predictions have the correct shape (batch_size, num_classes)\n",
        "        model_output = model.predict([batch_image, batch_chili])[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch([batch_image, batch_chili], batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model_with_shufflenet.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CP92uQcvcBU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Build the model\n",
        "def shufflenet_block(x, groups=1, name=None):\n",
        "    channel_axis = 1 if tf.keras.backend.image_data_format() == 'channels_first' else -1\n",
        "    in_channels = x.shape[channel_axis]\n",
        "\n",
        "    # Ensure that the number of input channels is divisible by the number of groups\n",
        "    if in_channels % groups != 0:\n",
        "        groups = in_channels  # Set groups to in_channels if not divisible\n",
        "\n",
        "    # Ensure that the number of filters is divisible by the number of groups\n",
        "    filters = in_channels // groups\n",
        "    filters = max(filters, groups)  # Set filters to groups if it becomes zero\n",
        "\n",
        "    # ShuffleNet block\n",
        "    x = layers.Conv2D(filters, (1, 1), groups=groups, activation='relu', name=name + '_gconv_1x1')(x)\n",
        "    x = layers.DepthwiseConv2D((3, 3), padding='same', use_bias=False, name=name + '_dwconv')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_dwconv_bn')(x)\n",
        "    x = layers.Conv2D(filters, (1, 1), activation='relu', name=name + '_pwconv_1x1')(x)\n",
        "    x = layers.BatchNormalization(axis=channel_axis, name=name + '_pwconv_bn')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# SE block\n",
        "def se_block(x, ratio=16):\n",
        "    channels = x.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([x, se])\n",
        "\n",
        "# MDSG-SE block\n",
        "def mdsg_se_block(x, filters):\n",
        "    # Branch 1 - Fine-grained features\n",
        "    branch1 = layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    branch1 = layers.BatchNormalization()(branch1)\n",
        "    branch1 = layers.Activation('relu')(branch1)\n",
        "    branch1 = se_block(branch1)\n",
        "\n",
        "    # Branch 2 - Coarse-grained features\n",
        "    branch2 = layers.Conv2D(filters, (5, 5), padding='same')(x)\n",
        "    branch2 = layers.BatchNormalization()(branch2)\n",
        "    branch2 = layers.Activation('relu')(branch2)\n",
        "    branch2 = se_block(branch2)\n",
        "\n",
        "    # Upsample branch 1 to match the shape of branch 2\n",
        "    branch1 = layers.UpSampling2D(size=(2, 2))(branch1)\n",
        "\n",
        "    # Crop branch 1 to have the same spatial dimensions as branch 2\n",
        "    crop_size = int(branch1.shape[1] - branch2.shape[1])\n",
        "    branch1 = layers.Cropping2D(cropping=((crop_size, 0), (crop_size, 0)))(branch1)\n",
        "\n",
        "    # Concatenate branches\n",
        "    merged = layers.Concatenate()([branch1, branch2])\n",
        "\n",
        "    # Dynamic channel gating\n",
        "    gating_weights = layers.Conv2D(filters, (1, 1), padding='same', activation='sigmoid')(merged)\n",
        "\n",
        "    # Apply gating to the input features\n",
        "    x = layers.Conv2D(filters, (1, 1), padding='same')(x)\n",
        "    gated_features = layers.Multiply()([x, gating_weights])\n",
        "\n",
        "    return gated_features\n",
        "\n",
        "# Input layers\n",
        "input_shape_image = (224, 224, 3)\n",
        "\n",
        "num_classes = 5  # Adjusted to match the number of classes in your dataset\n",
        "\n",
        "# Input layers\n",
        "input_layer_image = layers.Input(shape=input_shape_image, name='image_input')\n",
        "\n",
        "# Use MobileNetV2 as the base model for image features\n",
        "base_model_image = MobileNetV2(input_shape=input_shape_image, include_top=False, weights='imagenet')\n",
        "base_model_image.trainable = False  # Freeze base model weights\n",
        "image_features = base_model_image(input_layer_image)\n",
        "\n",
        "# Shufflenet block for image features\n",
        "shufflenet_block_image = shufflenet_block(image_features, groups=3, name='shufflenet_image')\n",
        "\n",
        "# Additional Convolutional Layers\n",
        "conv4 = layers.Conv2D(512, (3, 3), padding='same')(shufflenet_block_image)\n",
        "conv4 = layers.BatchNormalization()(conv4)\n",
        "conv4 = layers.Activation('relu')(conv4)\n",
        "\n",
        "# Flatten the features and add a Dense layer\n",
        "flatten = layers.Flatten()(conv4)\n",
        "dense1 = layers.Dense(512, activation='relu')(flatten)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense1)\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Model(inputs=input_layer_image, outputs=output_layer)\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)  # Adjusted learning rate\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Load your images using ImageDataGenerator with data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/classification/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=None  # Change this to None for automatic class detection\n",
        ")\n",
        "\n",
        "# Lists to store accuracy and loss values\n",
        "accuracy_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "steps_per_epoch = train_generator.samples // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "\n",
        "    for step in range(steps_per_epoch):\n",
        "        # Generate the next batch of data\n",
        "        batch_image, batch_label = train_generator.next()\n",
        "\n",
        "        # Convert it to a 1D array if it's not already\n",
        "        batch_label = np.ravel(batch_label)\n",
        "\n",
        "        # Convert batch_label to one-hot encoding\n",
        "        batch_label_one_hot = to_categorical(batch_label, num_classes=num_classes)\n",
        "\n",
        "        # Ensure batch_label_one_hot has the correct shape (batch_size, num_classes)\n",
        "        batch_label_one_hot = batch_label_one_hot[:batch_size]\n",
        "\n",
        "        # Train the model on the current batch\n",
        "        loss, accuracy = model.train_on_batch(batch_image, batch_label_one_hot)\n",
        "\n",
        "        # Update cumulative metrics\n",
        "        total_loss += loss\n",
        "        total_accuracy += accuracy\n",
        "\n",
        "    # Average loss and accuracy for the epoch\n",
        "    average_loss = total_loss / steps_per_epoch\n",
        "    average_accuracy = total_accuracy / steps_per_epoch\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {average_loss:.4f} - Accuracy: {average_accuracy:.4f}\")\n",
        "\n",
        "    # Append values to the lists\n",
        "    accuracy_values.append(average_accuracy)\n",
        "    loss_values.append(average_loss)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('my_model_training_only_images.keras')\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Plot training accuracy and loss values\n",
        "plt.plot(accuracy_values, label='Training Accuracy')\n",
        "plt.plot(loss_values, label='Training Loss')\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhUmXJd1UiO1"
      },
      "outputs": [],
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoFYOx9qUoCa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from keras_contrib.layers import Capsule\n",
        "\n",
        "def CapsuleNetwork(input_shape, num_classes):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Encoder\n",
        "    model.add(layers.Conv2D(256, (9, 9), activation='relu', padding='valid', input_shape=input_shape))\n",
        "    model.add(layers.Conv2D(256, (9, 9), activation='relu', padding='valid', strides=(2, 2)))\n",
        "\n",
        "    # Primary Capsule Layer\n",
        "    model.add(Capsule(32, 8, 3, True))\n",
        "\n",
        "    # Digit Capsule Layer\n",
        "    model.add(Capsule(num_classes, 16, 3, True))\n",
        "\n",
        "    # Decoder\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dense(1024, activation='relu'))\n",
        "    model.add(layers.Dense(tf.reduce_prod(input_shape), activation='sigmoid'))\n",
        "    model.add(layers.Reshape(target_shape=input_shape, name='decoder_output'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (256, 256, 3)  # Adjust based on your segmented image size\n",
        "num_classes = 10  # Adjust based on your dataset\n",
        "\n",
        "model = CapsuleNetwork(input_shape, num_classes)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IW-ncOhCeOMz"
      },
      "outputs": [],
      "source": [
        "pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlkmVmk5B_tU"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python scikit-learn tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUOnAx934YpO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.filters import gaussian\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# SE block definition\n",
        "def se_block(input_feature, ratio=16):\n",
        "    channel_axis = -1  # assuming channels-last\n",
        "    channels = input_feature.shape[channel_axis]\n",
        "    se_shape = (1, 1, channels)\n",
        "\n",
        "    se = layers.GlobalAveragePooling2D()(input_feature)\n",
        "    se = layers.Reshape(se_shape)(se)\n",
        "    se = layers.Dense(channels // ratio, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "\n",
        "    return layers.multiply([input_feature, se])\n",
        "\n",
        "# ShuffleNet-like block (simplified for demonstration)\n",
        "def shufflenet_block(input_feature, groups=1, name=None):\n",
        "    channels = input_feature.shape[-1]\n",
        "    grouped_channels = int(channels) // groups\n",
        "\n",
        "    # Grouped convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', groups=groups, use_bias=False)(input_feature)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Channel shuffle (omitted for simplicity)\n",
        "\n",
        "    # Pointwise convolution\n",
        "    x = layers.Conv2D(grouped_channels, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Custom data generator with Gaussian blur and K-means segmentation\n",
        "class CustomDataGenerator(ImageDataGenerator):\n",
        "    def __init__(self, blur_sigma=1, n_clusters=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.blur_sigma = blur_sigma\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def apply_preprocessing(self, img):\n",
        "        # Gaussian blur\n",
        "        blurred_img = gaussian(img, sigma=self.blur_sigma, multichannel=True)\n",
        "\n",
        "        # K-means segmentation\n",
        "        img_lab = rgb2lab(blurred_img)\n",
        "        img_lab = img_lab.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
        "        kmeans.fit(img_lab)\n",
        "        segmented_lab = kmeans.cluster_centers_[kmeans.labels_]\n",
        "        segmented_img = segmented_lab.reshape(blurred_img.shape)\n",
        "        segmented_img_rgb = lab2rgb(segmented_img)\n",
        "\n",
        "        return segmented_img_rgb\n",
        "\n",
        "    def random_transform(self, x, seed=None):\n",
        "        x = super().random_transform(x, seed)\n",
        "        return self.apply_preprocessing(x)\n",
        "\n",
        "# Model building\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = layers.Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Use MobileNetV2 as the base model\n",
        "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model(input_layer)\n",
        "    x = se_block(x)\n",
        "    x = shufflenet_block(x, groups=1, name='shufflenet_custom')\n",
        "\n",
        "    # Final part of the model\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 5\n",
        "\n",
        "# Create the custom data generator with Gaussian blur and K-means segmentation\n",
        "train_datagen = CustomDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    blur_sigma=2,  # Adjust as needed\n",
        "    n_clusters=3   # Adjust as needed\n",
        ")\n",
        "\n",
        "# Assuming you have a way to load and preprocess your dataset\n",
        "# Replace 'path/to/your/data' with the actual path to your dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Chili_Plant_Disease/val',\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Assuming you have a training subset\n",
        ")\n",
        "\n",
        "# Build the model\n",
        "model = build_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=10, steps_per_epoch=len(train_generator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJJCWvaEiR5-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.filters import gaussian\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# SE block definition with Multi-scale Dynamic Spatial Gating\n",
        "def se_block(input_feature, ratio=16):\n",
        "    channel_axis = -1  # assuming channels-last\n",
        "    channels = input_feature.shape[channel_axis]\n",
        "    se_shape = (1, 1, channels)\n",
        "\n",
        "    # Fine-grained attention\n",
        "    se_fine = layers.GlobalAveragePooling2D()(input_feature)\n",
        "    se_fine = layers.Reshape((1, 1, channels))(se_fine)\n",
        "    se_fine = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(se_fine)\n",
        "    se_fine = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_fine)\n",
        "    fine_grained = layers.multiply([input_feature, se_fine])\n",
        "\n",
        "    # Coarse-grained attention\n",
        "    se_coarse = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(input_feature)\n",
        "    se_coarse = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_coarse)\n",
        "    coarse_grained = layers.multiply([input_feature, se_coarse])\n",
        "\n",
        "    # Dynamic Spatial Gating\n",
        "    dynamic_gate = layers.Add()([fine_grained, coarse_grained])\n",
        "\n",
        "    return dynamic_gate\n",
        "\n",
        "# ShuffleNet-like block (simplified for demonstration)\n",
        "def shufflenet_block(input_feature, groups=1, name=None):\n",
        "    channels = input_feature.shape[-1]\n",
        "    grouped_channels = int(channels) // groups\n",
        "\n",
        "    # Grouped convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', groups=groups, use_bias=False)(input_feature)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Channel shuffle (omitted for simplicity)\n",
        "\n",
        "    # Pointwise convolution\n",
        "    x = layers.Conv2D(grouped_channels, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Custom data generator with Gaussian blur and K-means segmentation\n",
        "class CustomDataGenerator(ImageDataGenerator):\n",
        "    def __init__(self, blur_sigma=1, n_clusters=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.blur_sigma = blur_sigma\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def apply_preprocessing(self, img):\n",
        "        # Gaussian blur\n",
        "        blurred_img = gaussian(img, sigma=self.blur_sigma, multichannel=True)\n",
        "\n",
        "        # K-means segmentation\n",
        "        img_lab = rgb2lab(blurred_img)\n",
        "        img_lab = img_lab.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
        "        kmeans.fit(img_lab)\n",
        "        segmented_lab = kmeans.cluster_centers_[kmeans.labels_]\n",
        "        segmented_img = segmented_lab.reshape(blurred_img.shape)\n",
        "        segmented_img_rgb = lab2rgb(segmented_img)\n",
        "\n",
        "        return segmented_img_rgb\n",
        "\n",
        "    def random_transform(self, x, seed=None):\n",
        "        x = super().random_transform(x, seed)\n",
        "        return self.apply_preprocessing(x)\n",
        "\n",
        "# Model building\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = layers.Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Use MobileNetV2 as the base model\n",
        "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model(input_layer)\n",
        "    x = se_block(x)\n",
        "    x = shufflenet_block(x, groups=1, name='shufflenet_custom')\n",
        "\n",
        "    # Final part of the model\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 3\n",
        "\n",
        "# Create the custom data generator with Gaussian blur and K-means segmentation\n",
        "train_datagen = CustomDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    blur_sigma=2,  # Adjust as needed\n",
        "    n_clusters=3  # Adjust as needed\n",
        ")\n",
        "\n",
        "# Assuming you have a way to load and preprocess your dataset\n",
        "# Replace 'path/to/your/data' with the actual path to your dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/potato/PLD_3_Classes_256/Training',\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Assuming you have a training subset\n",
        ")\n",
        "\n",
        "# Build the model\n",
        "model = build_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=10, steps_per_epoch=len(train_generator))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMCTNAj0WzAY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.filters import gaussian\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# SE block definition with Multi-scale Dynamic Spatial Gating\n",
        "def se_block(input_feature, ratio=16):\n",
        "    channel_axis = -1  # assuming channels-last\n",
        "    channels = input_feature.shape[channel_axis]\n",
        "    se_shape = (1, 1, channels)\n",
        "\n",
        "    # Fine-grained attention\n",
        "    se_fine = layers.GlobalAveragePooling2D()(input_feature)\n",
        "    se_fine = layers.Reshape((1, 1, channels))(se_fine)\n",
        "    se_fine = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(se_fine)\n",
        "    se_fine = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_fine)\n",
        "    fine_grained = layers.multiply([input_feature, se_fine])\n",
        "\n",
        "    # Coarse-grained attention\n",
        "    se_coarse = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(input_feature)\n",
        "    se_coarse = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_coarse)\n",
        "    coarse_grained = layers.multiply([input_feature, se_coarse])\n",
        "\n",
        "    # Dynamic Spatial Gating\n",
        "    dynamic_gate = layers.Add()([fine_grained, coarse_grained])\n",
        "\n",
        "    return dynamic_gate\n",
        "\n",
        "# ShuffleNet-like block (simplified for demonstration)\n",
        "def shufflenet_block(input_feature, groups=1, name=None):\n",
        "    channels = input_feature.shape[-1]\n",
        "    grouped_channels = int(channels) // groups\n",
        "\n",
        "    # Grouped convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', groups=groups, use_bias=False)(input_feature)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Channel shuffle (omitted for simplicity)\n",
        "\n",
        "    # Pointwise convolution\n",
        "    x = layers.Conv2D(grouped_channels, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Custom data generator with Gaussian blur and K-means segmentation\n",
        "class CustomDataGenerator(ImageDataGenerator):\n",
        "    def __init__(self, blur_sigma=1, n_clusters=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.blur_sigma = blur_sigma\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def apply_preprocessing(self, img):\n",
        "        # Gaussian blur\n",
        "        blurred_img = gaussian(img, sigma=self.blur_sigma, multichannel=True)\n",
        "\n",
        "        # K-means segmentation\n",
        "        img_lab = rgb2lab(blurred_img)\n",
        "        img_lab = img_lab.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
        "        kmeans.fit(img_lab)\n",
        "        segmented_lab = kmeans.cluster_centers_[kmeans.labels_]\n",
        "        segmented_img = segmented_lab.reshape(blurred_img.shape)\n",
        "        segmented_img_rgb = lab2rgb(segmented_img)\n",
        "\n",
        "        return segmented_img_rgb\n",
        "\n",
        "    def random_transform(self, x, seed=None):\n",
        "        x = super().random_transform(x, seed)\n",
        "        return self.apply_preprocessing(x)\n",
        "\n",
        "# Model building\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = layers.Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Use MobileNetV2 as the base model\n",
        "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model(input_layer)\n",
        "    x = se_block(x)\n",
        "    x = shufflenet_block(x, groups=1, name='shufflenet_custom')\n",
        "\n",
        "    # Final part of the model\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 4\n",
        "\n",
        "# Create the custom data generator with Gaussian blur and K-means segmentation\n",
        "train_datagen = CustomDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    blur_sigma=2,  # Adjust as needed\n",
        "    n_clusters=3   # Adjust as needed\n",
        ")\n",
        "\n",
        "# Assuming you have a way to load and preprocess your dataset\n",
        "# Replace 'path/to/your/data' with the actual path to your dataset\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/APPLE_DISEASE_DATASET',\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Assuming you have a training subset\n",
        ")\n",
        "# Build the model\n",
        "model = build_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "# Train the model and capture the history\n",
        "history = model.fit(train_generator, epochs=10, steps_per_epoch=len(train_generator))\n",
        "\n",
        "\n",
        "\n",
        "# Display training loss and accuracy in one graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.title('Training Loss and Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Plot training accuracy on the same graph\n",
        "plt.twinx()  # Create a second y-axis to overlay accuracy on the same plot\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='green')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE4Yzi3FQrLH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSX3lQnQjlyY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yurbcdOB05Os"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_dataset(dataset_path):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for category in os.listdir(dataset_path):\n",
        "        category_path = os.path.join(dataset_path, category)\n",
        "\n",
        "        if not os.path.isdir(category_path):\n",
        "            continue  # Skip non-directory entries\n",
        "\n",
        "        for image_name in os.listdir(category_path):\n",
        "            image_path = os.path.join(category_path, image_name)\n",
        "\n",
        "            if not os.path.isfile(image_path):\n",
        "                continue  # Skip non-file entries\n",
        "\n",
        "            img = cv2.imread(image_path)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"Error loading image: {image_path}\")\n",
        "                continue  # Skip if the image cannot be loaded\n",
        "\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "            img_flat = img.reshape((-1, 3))\n",
        "\n",
        "            kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "            kmeans.fit(img_flat)\n",
        "            segmented_img = kmeans.cluster_centers_[kmeans.labels_].reshape(img.shape)\n",
        "\n",
        "            img = cv2.resize(segmented_img, (224, 224))\n",
        "\n",
        "            data.append(img)\n",
        "            labels.append(category)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Specify your dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/Chili_Plant_Disease/test\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "X, y = load_dataset(dataset_path)\n",
        "\n",
        "# Perform one-hot encoding on the labels\n",
        "label_dict = {label: idx for idx, label in enumerate(np.unique(y))}\n",
        "y = [label_dict[label] for label in y]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(label_dict))\n",
        "\n",
        "# Split the dataset into training, testing, and validation sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build Disease-aware Multimodal Feature Fusion with Capsule Network model\n",
        "class PrimaryCapsuleLayer(layers.Layer):\n",
        "    def __init__(self, num_capsules, capsule_dim, routings=3, kernel_size=(9, 9), strides=(2, 2), padding='valid'):\n",
        "        super(PrimaryCapsuleLayer, self).__init__()\n",
        "        self.capsule_dim = capsule_dim\n",
        "        self.conv2d = layers.Conv2D(num_capsules * capsule_dim, kernel_size, strides=strides, padding=padding)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.reshape(self.conv2d(inputs), (tf.shape(inputs)[0], -1, self.capsule_dim))\n",
        "\n",
        "class GlobalAveragePooling2DByDim(layers.Layer):\n",
        "    def __init__(self, dim):\n",
        "        super(GlobalAveragePooling2DByDim, self).__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.reduce_mean(inputs, axis=self.dim)\n",
        "\n",
        "# Define your capsule network model\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = len(label_dict)\n",
        "\n",
        "input_layer = layers.Input(shape=input_shape)\n",
        "primary_capsule_layer = PrimaryCapsuleLayer(num_capsules=32, capsule_dim=8)(input_layer)\n",
        "global_avg_pooling_layer = GlobalAveragePooling2DByDim(dim=1)(primary_capsule_layer)\n",
        "\n",
        "dense_layer = layers.Dense(128, activation='relu')(global_avg_pooling_layer)\n",
        "output_layer = layers.Dense(num_classes, activation='softmax')(dense_layer)\n",
        "\n",
        "model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and collect history\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy}, Test Loss: {test_loss}')\n",
        "\n",
        "# Plot all accuracies and losses in one graph\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.axhline(y=test_loss, color='g', linestyle='--', label='Test Loss')\n",
        "\n",
        "plt.title('Model Accuracy and Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train Accuracy', 'Validation Accuracy', 'Test Accuracy', 'Train Loss', 'Validation Loss', 'Test Loss'], loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANi59mKVimSI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.filters import gaussian\n",
        "from sklearn.cluster import KMeans\n",
        "# SE block definition with Multi-scale Dynamic Spatial Gating\n",
        "def se_block(input_feature, ratio=16):\n",
        "    channel_axis = -1  # assuming channels-last\n",
        "    channels = input_feature.shape[channel_axis]\n",
        "    se_shape = (1, 1, channels)\n",
        "\n",
        "    # Fine-grained attention\n",
        "    se_fine = layers.GlobalAveragePooling2D()(input_feature)\n",
        "    se_fine = layers.Reshape((1, 1, channels))(se_fine)\n",
        "    se_fine = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(se_fine)\n",
        "    se_fine = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_fine)\n",
        "    fine_grained = layers.multiply([input_feature, se_fine])\n",
        "\n",
        "    # Coarse-grained attention\n",
        "    se_coarse = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(input_feature)\n",
        "    se_coarse = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_coarse)\n",
        "    coarse_grained = layers.multiply([input_feature, se_coarse])\n",
        "\n",
        "    # Dynamic Spatial Gating\n",
        "    dynamic_gate = layers.Add()([fine_grained, coarse_grained])\n",
        "\n",
        "    return dynamic_gate\n",
        "\n",
        "# ShuffleNet-like block (simplified for demonstration)\n",
        "def shufflenet_block(input_feature, groups=1, name=None):\n",
        "    channels = input_feature.shape[-1]\n",
        "    grouped_channels = int(channels) // groups\n",
        "\n",
        "    # Grouped convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', groups=groups, use_bias=False)(input_feature)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Channel shuffle (omitted for simplicity)\n",
        "\n",
        "    # Pointwise convolution\n",
        "    x = layers.Conv2D(grouped_channels, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Custom data generator with Gaussian blur and K-means segmentation\n",
        "class CustomDataGenerator(ImageDataGenerator):\n",
        "    def __init__(self, blur_sigma=1, n_clusters=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.blur_sigma = blur_sigma\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def apply_preprocessing(self, img):\n",
        "        # Gaussian blur\n",
        "        blurred_img = gaussian(img, sigma=self.blur_sigma, multichannel=True)\n",
        "\n",
        "        # K-means segmentation\n",
        "        img_lab = rgb2lab(blurred_img)\n",
        "        img_lab = img_lab.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
        "        kmeans.fit(img_lab)\n",
        "        segmented_lab = kmeans.cluster_centers_[kmeans.labels_]\n",
        "        segmented_img = segmented_lab.reshape(blurred_img.shape)\n",
        "        segmented_img_rgb = lab2rgb(segmented_img)\n",
        "\n",
        "        return segmented_img_rgb\n",
        "\n",
        "    def random_transform(self, x, seed=None):\n",
        "        x = super().random_transform(x, seed)\n",
        "        return self.apply_preprocessing(x)\n",
        "\n",
        "# Model building\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = layers.Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Use MobileNetV2 as the base model\n",
        "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model(input_layer)\n",
        "    x = se_block(x)\n",
        "    x = shufflenet_block(x, groups=1, name='shufflenet_custom')\n",
        "\n",
        "    # Final part of the model\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 6\n",
        "\n",
        "# Create the custom data generator with Gaussian blur and K-means segmentation\n",
        "train_datagen = CustomDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    blur_sigma=2,  # Adjust as needed\n",
        "    n_clusters=3   # Adjust as needed\n",
        ")\n",
        "\n",
        "# Assuming you have a way to load and preprocess your dataset\n",
        "# Replace 'path/to/your/data' with the actual path to your dataset\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/40 Images',\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Assuming you have a training subset\n",
        ")\n",
        "\n",
        "# Build the model,\n",
        "model = build_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "# Train the model and capture the history\n",
        "history = model.fit(train_generator, epochs=30, steps_per_epoch=len(train_generator))\n",
        "\n",
        "\n",
        "# Display training loss and accuracy in one graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.title('Training Loss and Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Plot training accuracy on the same graph\n",
        "plt.twinx()  # Create a second y-axis to overlay accuracy on the same plot\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='green')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL6FQAxzduzg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxybM62YCkPz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.filters import gaussian\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# SE block definition with Multi-scale Dynamic Spatial Gating\n",
        "def se_block(input_feature, ratio=16):\n",
        "    channel_axis = -1  # assuming channels-last\n",
        "    channels = input_feature.shape[channel_axis]\n",
        "    se_shape = (1, 1, channels)\n",
        "\n",
        "    # Fine-grained attention\n",
        "    se_fine = layers.GlobalAveragePooling2D()(input_feature)\n",
        "    se_fine = layers.Reshape((1, 1, channels))(se_fine)\n",
        "    se_fine = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(se_fine)\n",
        "    se_fine = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_fine)\n",
        "    fine_grained = layers.multiply([input_feature, se_fine])\n",
        "\n",
        "    # Coarse-grained attention\n",
        "    se_coarse = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(input_feature)\n",
        "    se_coarse = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_coarse)\n",
        "    coarse_grained = layers.multiply([input_feature, se_coarse])\n",
        "\n",
        "    # Dynamic Spatial Gating\n",
        "    dynamic_gate = layers.Add()([fine_grained, coarse_grained])\n",
        "\n",
        "    return dynamic_gate\n",
        "\n",
        "# ShuffleNet-like block (simplified for demonstration)\n",
        "def shufflenet_block(input_feature, groups=1, name=None):\n",
        "    channels = input_feature.shape[-1]\n",
        "    grouped_channels = int(channels) // groups\n",
        "\n",
        "    # Grouped convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', groups=groups, use_bias=False)(input_feature)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Pointwise convolution\n",
        "    x = layers.Conv2D(grouped_channels, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Custom data generator with Gaussian blur and K-means segmentation\n",
        "class CustomDataGenerator(ImageDataGenerator):\n",
        "    def __init__(self, blur_sigma=1, n_clusters=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.blur_sigma = blur_sigma\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def apply_preprocessing(self, img):\n",
        "        # Gaussian blur\n",
        "        blurred_img = gaussian(img, sigma=self.blur_sigma, multichannel=True)\n",
        "\n",
        "        # K-means segmentation\n",
        "        img_lab = rgb2lab(blurred_img)\n",
        "        img_lab = img_lab.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
        "        kmeans.fit(img_lab)\n",
        "        segmented_lab = kmeans.cluster_centers_[kmeans.labels_]\n",
        "        segmented_img = segmented_lab.reshape(blurred_img.shape)\n",
        "        segmented_img_rgb = lab2rgb(segmented_img)\n",
        "\n",
        "        return segmented_img_rgb\n",
        "\n",
        "    def random_transform(self, x, seed=None):\n",
        "        x = super().random_transform(x, seed)\n",
        "        return self.apply_preprocessing(x)\n",
        "\n",
        "# Model building\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = layers.Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Use MobileNetV2 as the base model\n",
        "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model(input_layer)\n",
        "    x = se_block(x)\n",
        "    x = shufflenet_block(x, groups=1, name='shufflenet_custom')\n",
        "\n",
        "    # Final part of the model\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 3\n",
        "\n",
        "# Create the custom data generator with Gaussian blur and K-means segmentation\n",
        "train_datagen = CustomDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    blur_sigma=2,  # Adjust as needed\n",
        "    n_clusters=3   # Adjust as needed\n",
        ")\n",
        "\n",
        "# Assuming you have a way to load and preprocess your dataset\n",
        "# Replace 'path/to/your/data' with the actual path to your dataset\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/potato dataset/PLD_3_Classes_256/Testing',\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Assuming you have a training subset\n",
        ")\n",
        "\n",
        "# Build the model\n",
        "model = build_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=10, steps_per_epoch=len(train_generator))\n",
        "\n",
        "# Display training loss and accuracy in one graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.title('Training Loss and Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Plot training accuracy on the same graph\n",
        "plt.twinx()  # Create a second y-axis to overlay accuracy on the same plot\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='green')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(train_generator)\n",
        "print(f'Training Loss: {train_loss:.4f}')\n",
        "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
        "\n",
        "# Predict classes for the test set\n",
        "y_pred = model.predict(train_generator)\n",
        "y_true = train_generator.classes\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, np.argmax(y_pred, axis=1))\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=train_generator.class_indices.keys(), yticklabels=train_generator.class_indices.keys())\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Display classification report\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "classification_rep = classification_report(y_true, np.argmax(y_pred, axis=1), target_names=class_labels)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4gEGDGDgrp1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1beksV0zgsRZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.filters import gaussian\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# SE block definition with Multi-scale Dynamic Spatial Gating\n",
        "def se_block(input_feature, ratio=16):\n",
        "    channel_axis = -1  # assuming channels-last\n",
        "    channels = input_feature.shape[channel_axis]\n",
        "    se_shape = (1, 1, channels)\n",
        "\n",
        "    # Fine-grained attention\n",
        "    se_fine = layers.GlobalAveragePooling2D()(input_feature)\n",
        "    se_fine = layers.Reshape((1, 1, channels))(se_fine)\n",
        "    se_fine = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(se_fine)\n",
        "    se_fine = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_fine)\n",
        "    fine_grained = layers.multiply([input_feature, se_fine])\n",
        "\n",
        "    # Coarse-grained attention\n",
        "    se_coarse = layers.Conv2D(channels // ratio, kernel_size=1, activation='relu', padding='same')(input_feature)\n",
        "    se_coarse = layers.Conv2D(channels, kernel_size=1, activation='sigmoid', padding='same')(se_coarse)\n",
        "    coarse_grained = layers.multiply([input_feature, se_coarse])\n",
        "\n",
        "    # Dynamic Spatial Gating\n",
        "    dynamic_gate = layers.Add()([fine_grained, coarse_grained])\n",
        "\n",
        "    return dynamic_gate\n",
        "\n",
        "# ShuffleNet-like block (simplified for demonstration)\n",
        "def shufflenet_block(input_feature, groups=1, name=None):\n",
        "    channels = input_feature.shape[-1]\n",
        "    grouped_channels = int(channels) // groups\n",
        "\n",
        "    # Grouped convolution\n",
        "    x = layers.DepthwiseConv2D(kernel_size=3, strides=1, padding='same', groups=groups, use_bias=False)(input_feature)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    # Pointwise convolution\n",
        "    x = layers.Conv2D(grouped_channels, kernel_size=1, strides=1, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Custom data generator with Gaussian blur and K-means segmentation\n",
        "class CustomDataGenerator(ImageDataGenerator):\n",
        "    def __init__(self, blur_sigma=1, n_clusters=3, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.blur_sigma = blur_sigma\n",
        "        self.n_clusters = n_clusters\n",
        "\n",
        "    def apply_preprocessing(self, img):\n",
        "        # Gaussian blur\n",
        "        blurred_img = gaussian(img, sigma=self.blur_sigma, multichannel=True)\n",
        "\n",
        "        # K-means segmentation\n",
        "        img_lab = rgb2lab(blurred_img)\n",
        "        img_lab = img_lab.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
        "        kmeans.fit(img_lab)\n",
        "        segmented_lab = kmeans.cluster_centers_[kmeans.labels_]\n",
        "        segmented_img = segmented_lab.reshape(blurred_img.shape)\n",
        "        segmented_img_rgb = lab2rgb(segmented_img)\n",
        "\n",
        "        return segmented_img_rgb\n",
        "\n",
        "    def random_transform(self, x, seed=None):\n",
        "        x = super().random_transform(x, seed)\n",
        "        return self.apply_preprocessing(x)\n",
        "\n",
        "# Model building\n",
        "def build_model(input_shape, num_classes):\n",
        "    input_layer = layers.Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Use MobileNetV2 as the base model\n",
        "    base_model = MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    x = base_model(input_layer)\n",
        "    x = se_block(x)\n",
        "    x = shufflenet_block(x, groups=1, name='shufflenet_custom')\n",
        "\n",
        "    # Final part of the model\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    output_layer = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 6\n",
        "\n",
        "# Create the custom data generator with Gaussian blur and K-means segmentation\n",
        "train_datagen = CustomDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    blur_sigma=2,  # Adjust as needed\n",
        "    n_clusters=3   # Adjust as needed\n",
        ")\n",
        "\n",
        "# Assuming you have a way to load and preprocess your dataset\n",
        "# Replace 'path/to/your/data' with the actual path to your dataset\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/MyDrive/cotton dataset/Cotton leaves/40 Images',\n",
        "    target_size=input_shape[:2],\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'  # Assuming you have a training subset\n",
        ")\n",
        "\n",
        "# Build the model\n",
        "model = build_model(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=30, steps_per_epoch=len(train_generator))\n",
        "\n",
        "# Display training loss and accuracy in one graph\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training loss\n",
        "plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "plt.title('Training Loss and Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')\n",
        "\n",
        "# Plot training accuracy on the same graph\n",
        "plt.twinx()  # Create a second y-axis to overlay accuracy on the same plot\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy', color='green')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_loss, train_accuracy = model.evaluate(train_generator)\n",
        "print(f'Training Loss: {train_loss:.4f}')\n",
        "print(f'Training Accuracy: {train_accuracy:.4f}')\n",
        "\n",
        "# Predict classes for the test set\n",
        "y_pred = model.predict(train_generator)\n",
        "y_true = train_generator.classes\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, np.argmax(y_pred, axis=1))\n",
        "\n",
        "# Display confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=train_generator.class_indices.keys(), yticklabels=train_generator.class_indices.keys())\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Display classification report\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "classification_rep = classification_report(y_true, np.argmax(y_pred, axis=1), target_names=class_labels)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPUERV0g8c7L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape\n",
        "from keras_contrib.layers import Capsule\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/Chili dataset/test\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_and_preprocess_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for label in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label)\n",
        "        for image_name in os.listdir(label_path):\n",
        "            image_path = os.path.join(label_path, image_name)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            image = cv2.resize(image, (28, 28)) / 255.0  # Resize and normalize\n",
        "            images.append(image)\n",
        "            labels.append(int(label))  # Assuming folder names are the class labels\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels = load_and_preprocess_dataset(os.path.join(dataset_path, \"train\"))\n",
        "test_images, test_labels = load_and_preprocess_dataset(os.path.join(dataset_path, \"test\"))\n",
        "\n",
        "# Preprocessing (Gaussian Blur)\n",
        "def preprocess_gaussian_blur(image):\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Apply Gaussian Blur\n",
        "    return blurred_image\n",
        "\n",
        "train_images_blurred = np.array([preprocess_gaussian_blur(img) for img in train_images])\n",
        "test_images_blurred = np.array([preprocess_gaussian_blur(img) for img in test_images])\n",
        "\n",
        "# Segmentation (K-Means)\n",
        "def kmeans_segmentation(image, num_clusters):\n",
        "    reshaped_image = image.reshape((-1, 1))  # Reshape image for K-Means\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_image = segmented_image.reshape(image.shape)\n",
        "    return segmented_image\n",
        "\n",
        "num_clusters = 3\n",
        "train_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in train_images_blurred])\n",
        "test_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in test_images_blurred])\n",
        "\n",
        "# Double Transfer Learning Model\n",
        "input_shape = (28, 28, 1)\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Pre-trained CNN model (Phase 1)\n",
        "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Capsule network (Phase 2)\n",
        "def create_capsule_network(base_model, num_classes):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    digit_caps = Capsule(num_classes, 16, 3, True)(x)\n",
        "    outputs = Reshape((num_classes,))(digit_caps)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_capsule_network(base_model, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning (Phase 2)\n",
        "model.fit(train_images_segmented[..., np.newaxis], train_labels, epochs=10, validation_split=0.1)\n",
        "\n",
        "# Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(test_images_segmented[..., np.newaxis], test_labels)\n",
        "predictions = model.predict(test_images_segmented[..., np.newaxis])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.imshow(conf_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzWCOoSVY3_2"
      },
      "outputs": [],
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE4WXLh4YLQT"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/Chili dataset\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_and_preprocess_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_dict = {}  # Dictionary to map label names to integers\n",
        "    label_count = 0\n",
        "    for label in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label)\n",
        "        if os.path.isdir(label_path):  # Check if it's a directory\n",
        "            label_dict[label] = label_count\n",
        "            for image_name in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_name)\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                image = cv2.resize(image, (224, 224))  # Resize\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
        "                images.append(image_rgb)\n",
        "                labels.append(label_count)  # Use integer label\n",
        "            label_count += 1\n",
        "    return np.array(images), np.array(labels), label_dict\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, label_dict = load_and_preprocess_dataset(os.path.join(dataset_path, \"train\"))\n",
        "test_images, test_labels, _ = load_and_preprocess_dataset(os.path.join(dataset_path, \"test\"))\n",
        "\n",
        "# Check the shapes of loaded data\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Preprocessing (Gaussian Blur)\n",
        "def preprocess_gaussian_blur(image):\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Apply Gaussian Blur\n",
        "    return blurred_image\n",
        "\n",
        "train_images_blurred = np.array([preprocess_gaussian_blur(img) for img in train_images])\n",
        "test_images_blurred = np.array([preprocess_gaussian_blur(img) for img in test_images])\n",
        "\n",
        "# Segmentation (K-Means)\n",
        "def kmeans_segmentation(image, num_clusters):\n",
        "    reshaped_image = image.reshape((-1, 1))  # Reshape image for K-Means\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_image = segmented_image.reshape(image.shape)\n",
        "    return segmented_image\n",
        "\n",
        "num_clusters = 3\n",
        "train_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in train_images_blurred])\n",
        "test_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in test_images_blurred])\n",
        "\n",
        "# Print shapes after preprocessing\n",
        "print(\"Train images segmented shape:\", train_images_segmented.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images segmented shape:\", test_images_segmented.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Double Transfer Learning Model\n",
        "input_shape = (224, 224, 3)  # Update input shape to 3 channels\n",
        "num_classes = len(label_dict)\n",
        "\n",
        "# Pre-trained CNN model (Phase 1)\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Capsule network (Phase 2)\n",
        "def create_capsule_network(base_model, num_classes):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_capsule_network(base_model, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning (Phase 2)\n",
        "history = model.fit(train_images_segmented[..., np.newaxis], train_labels, epochs=30)\n",
        "\n",
        "# Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(test_images_segmented[..., np.newaxis], test_labels)\n",
        "predictions = model.predict(test_images_segmented[..., np.newaxis])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "precision = precision_score(test_labels, predicted_classes, average='weighted')\n",
        "recall = recall_score(test_labels, predicted_classes, average='weighted')\n",
        "f_score = f1_score(test_labels, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", f_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix with values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZJmgsXBlYT5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAPS2kR5zAuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/corn dataset\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_and_preprocess_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_dict = {}  # Dictionary to map label names to integers\n",
        "    label_count = 0\n",
        "    for label in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label)\n",
        "        if os.path.isdir(label_path):  # Check if it's a directory\n",
        "            label_dict[label] = label_count\n",
        "            for image_name in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_name)\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                image = cv2.resize(image, (224, 224))  # Resize\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
        "                images.append(image_rgb)\n",
        "                labels.append(label_count)  # Use integer label\n",
        "            label_count += 1\n",
        "    return np.array(images), np.array(labels), label_dict\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, label_dict = load_and_preprocess_dataset(os.path.join(dataset_path, \"train\"))\n",
        "test_images, test_labels, _ = load_and_preprocess_dataset(os.path.join(dataset_path, \"test\"))\n",
        "\n",
        "# Check the shapes of loaded data\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Preprocessing (Gaussian Blur)\n",
        "def preprocess_gaussian_blur(image):\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Apply Gaussian Blur\n",
        "    return blurred_image\n",
        "\n",
        "train_images_blurred = np.array([preprocess_gaussian_blur(img) for img in train_images])\n",
        "test_images_blurred = np.array([preprocess_gaussian_blur(img) for img in test_images])\n",
        "\n",
        "# Segmentation (K-Means)\n",
        "def kmeans_segmentation(image, num_clusters):\n",
        "    reshaped_image = image.reshape((-1, 1))  # Reshape image for K-Means\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_image = segmented_image.reshape(image.shape)\n",
        "    return segmented_image\n",
        "\n",
        "num_clusters = 3\n",
        "train_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in train_images_blurred])\n",
        "test_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in test_images_blurred])\n",
        "\n",
        "# Print shapes after preprocessing\n",
        "print(\"Train images segmented shape:\", train_images_segmented.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images segmented shape:\", test_images_segmented.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Double Transfer Learning Model\n",
        "input_shape = (224, 224, 3)  # Update input shape to 3 channels\n",
        "num_classes = len(label_dict)\n",
        "\n",
        "# Pre-trained CNN model (Phase 1)\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Capsule network (Phase 2)\n",
        "def create_capsule_network(base_model, num_classes):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_capsule_network(base_model, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning (Phase 2)\n",
        "history = model.fit(train_images_segmented[..., np.newaxis], train_labels, epochs=30)\n",
        "\n",
        "# Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(test_images_segmented[..., np.newaxis], test_labels)\n",
        "predictions = model.predict(test_images_segmented[..., np.newaxis])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "precision = precision_score(test_labels, predicted_classes, average='weighted')\n",
        "recall = recall_score(test_labels, predicted_classes, average='weighted')\n",
        "f_score = f1_score(test_labels, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", f_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix with values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bkaX0gcIzC3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6yMmHEa1671"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/cotton dataset\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_and_preprocess_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_dict = {}  # Dictionary to map label names to integers\n",
        "    label_count = 0\n",
        "    for label in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label)\n",
        "        if os.path.isdir(label_path):  # Check if it's a directory\n",
        "            label_dict[label] = label_count\n",
        "            for image_name in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_name)\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                image = cv2.resize(image, (224, 224))  # Resize\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
        "                images.append(image_rgb)\n",
        "                labels.append(label_count)  # Use integer label\n",
        "            label_count += 1\n",
        "    return np.array(images), np.array(labels), label_dict\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, label_dict = load_and_preprocess_dataset(os.path.join(dataset_path, \"train\"))\n",
        "test_images, test_labels, _ = load_and_preprocess_dataset(os.path.join(dataset_path, \"test\"))\n",
        "\n",
        "# Check the shapes of loaded data\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Preprocessing (Gaussian Blur)\n",
        "def preprocess_gaussian_blur(image):\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Apply Gaussian Blur\n",
        "    return blurred_image\n",
        "\n",
        "train_images_blurred = np.array([preprocess_gaussian_blur(img) for img in train_images])\n",
        "test_images_blurred = np.array([preprocess_gaussian_blur(img) for img in test_images])\n",
        "\n",
        "# Segmentation (K-Means)\n",
        "def kmeans_segmentation(image, num_clusters):\n",
        "    reshaped_image = image.reshape((-1, 1))  # Reshape image for K-Means\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_image = segmented_image.reshape(image.shape)\n",
        "    return segmented_image\n",
        "\n",
        "num_clusters = 3\n",
        "train_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in train_images_blurred])\n",
        "test_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in test_images_blurred])\n",
        "\n",
        "# Print shapes after preprocessing\n",
        "print(\"Train images segmented shape:\", train_images_segmented.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images segmented shape:\", test_images_segmented.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Double Transfer Learning Model\n",
        "input_shape = (224, 224, 3)  # Update input shape to 3 channels\n",
        "num_classes = len(label_dict)\n",
        "\n",
        "# Pre-trained CNN model (Phase 1)\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Capsule network (Phase 2)\n",
        "def create_capsule_network(base_model, num_classes):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_capsule_network(base_model, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning (Phase 2)\n",
        "history = model.fit(train_images_segmented[..., np.newaxis], train_labels, epochs=30)\n",
        "\n",
        "# Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(test_images_segmented[..., np.newaxis], test_labels)\n",
        "predictions = model.predict(test_images_segmented[..., np.newaxis])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "precision = precision_score(test_labels, predicted_classes, average='weighted')\n",
        "recall = recall_score(test_labels, predicted_classes, average='weighted')\n",
        "f_score = f1_score(test_labels, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", f_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix with values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Tiyr0UGo2VFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-hG3B8PLnwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/apple dataset\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_and_preprocess_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_dict = {}  # Dictionary to map label names to integers\n",
        "    label_count = 0\n",
        "    for label in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label)\n",
        "        if os.path.isdir(label_path):  # Check if it's a directory\n",
        "            label_dict[label] = label_count\n",
        "            for image_name in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_name)\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                image = cv2.resize(image, (224, 224))  # Resize\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
        "                images.append(image_rgb)\n",
        "                labels.append(label_count)  # Use integer label\n",
        "            label_count += 1\n",
        "    return np.array(images), np.array(labels), label_dict\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, label_dict = load_and_preprocess_dataset(os.path.join(dataset_path, \"train\"))\n",
        "test_images, test_labels, _ = load_and_preprocess_dataset(os.path.join(dataset_path, \"test\"))\n",
        "\n",
        "# Check the shapes of loaded data\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Preprocessing (Gaussian Blur)\n",
        "def preprocess_gaussian_blur(image):\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Apply Gaussian Blur\n",
        "    return blurred_image\n",
        "\n",
        "train_images_blurred = np.array([preprocess_gaussian_blur(img) for img in train_images])\n",
        "test_images_blurred = np.array([preprocess_gaussian_blur(img) for img in test_images])\n",
        "\n",
        "# Segmentation (K-Means)\n",
        "def kmeans_segmentation(image, num_clusters):\n",
        "    reshaped_image = image.reshape((-1, 1))  # Reshape image for K-Means\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_image = segmented_image.reshape(image.shape)\n",
        "    return segmented_image\n",
        "\n",
        "num_clusters = 3\n",
        "train_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in train_images_blurred])\n",
        "test_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in test_images_blurred])\n",
        "\n",
        "# Print shapes after preprocessing\n",
        "print(\"Train images segmented shape:\", train_images_segmented.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images segmented shape:\", test_images_segmented.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Double Transfer Learning Model\n",
        "input_shape = (224, 224, 3)  # Update input shape to 3 channels\n",
        "num_classes = len(label_dict)\n",
        "\n",
        "# Pre-trained CNN model (Phase 1)\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Capsule network (Phase 2)\n",
        "def create_capsule_network(base_model, num_classes):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_capsule_network(base_model, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning (Phase 2)\n",
        "history = model.fit(train_images_segmented[..., np.newaxis], train_labels, epochs=30)\n",
        "\n",
        "# Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(test_images_segmented[..., np.newaxis], test_labels)\n",
        "predictions = model.predict(test_images_segmented[..., np.newaxis])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "precision = precision_score(test_labels, predicted_classes, average='weighted')\n",
        "recall = recall_score(test_labels, predicted_classes, average='weighted')\n",
        "f_score = f1_score(test_labels, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", f_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix with values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "j33fe4_0LoCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Reshape\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/potato Dataset\"\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "def load_and_preprocess_dataset(dataset_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_dict = {}  # Dictionary to map label names to integers\n",
        "    label_count = 0\n",
        "    for label in os.listdir(dataset_path):\n",
        "        label_path = os.path.join(dataset_path, label)\n",
        "        if os.path.isdir(label_path):  # Check if it's a directory\n",
        "            label_dict[label] = label_count\n",
        "            for image_name in os.listdir(label_path):\n",
        "                image_path = os.path.join(label_path, image_name)\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "                image = cv2.resize(image, (224, 224))  # Resize\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
        "                images.append(image_rgb)\n",
        "                labels.append(label_count)  # Use integer label\n",
        "            label_count += 1\n",
        "    return np.array(images), np.array(labels), label_dict\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "train_images, train_labels, label_dict = load_and_preprocess_dataset(os.path.join(dataset_path, \"train\"))\n",
        "test_images, test_labels, _ = load_and_preprocess_dataset(os.path.join(dataset_path, \"test\"))\n",
        "\n",
        "# Check the shapes of loaded data\n",
        "print(\"Train images shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images shape:\", test_images.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Preprocessing (Gaussian Blur)\n",
        "def preprocess_gaussian_blur(image):\n",
        "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # Apply Gaussian Blur\n",
        "    return blurred_image\n",
        "\n",
        "train_images_blurred = np.array([preprocess_gaussian_blur(img) for img in train_images])\n",
        "test_images_blurred = np.array([preprocess_gaussian_blur(img) for img in test_images])\n",
        "\n",
        "# Segmentation (K-Means)\n",
        "def kmeans_segmentation(image, num_clusters):\n",
        "    reshaped_image = image.reshape((-1, 1))  # Reshape image for K-Means\n",
        "    kmeans = KMeans(n_clusters=num_clusters)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_]\n",
        "    segmented_image = segmented_image.reshape(image.shape)\n",
        "    return segmented_image\n",
        "\n",
        "num_clusters = 3\n",
        "train_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in train_images_blurred])\n",
        "test_images_segmented = np.array([kmeans_segmentation(img, num_clusters) for img in test_images_blurred])\n",
        "\n",
        "# Print shapes after preprocessing\n",
        "print(\"Train images segmented shape:\", train_images_segmented.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Test images segmented shape:\", test_images_segmented.shape)\n",
        "print(\"Test labels shape:\", test_labels.shape)\n",
        "\n",
        "# Double Transfer Learning Model\n",
        "input_shape = (224, 224, 3)  # Update input shape to 3 channels\n",
        "num_classes = len(label_dict)\n",
        "\n",
        "# Pre-trained CNN model (Phase 1)\n",
        "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Capsule network (Phase 2)\n",
        "def create_capsule_network(base_model, num_classes):\n",
        "    x = base_model.output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = create_capsule_network(base_model, num_classes)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuning (Phase 2)\n",
        "history = model.fit(train_images_segmented[..., np.newaxis], train_labels, epochs=30)\n",
        "\n",
        "# Evaluation\n",
        "test_loss, test_accuracy = model.evaluate(test_images_segmented[..., np.newaxis], test_labels)\n",
        "predictions = model.predict(test_images_segmented[..., np.newaxis])\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "conf_matrix = confusion_matrix(test_labels, predicted_classes)\n",
        "\n",
        "precision = precision_score(test_labels, predicted_classes, average='weighted')\n",
        "recall = recall_score(test_labels, predicted_classes, average='weighted')\n",
        "f_score = f1_score(test_labels, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F-score:\", f_score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix with values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(conf_matrix, cmap='Blues')\n",
        "plt.colorbar()\n",
        "\n",
        "# Add text annotations\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        plt.text(j, i, conf_matrix[i, j], ha='center', va='center', color='black')\n",
        "\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.title('Training Accuracy and Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pgghwv416c-D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1QoOfM3W8QWz0-whPyPVWBjcWs-NOcTp6",
      "authorship_tag": "ABX9TyOyMSYBcIAzOMAuvzwhJq96",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}