{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rathiya-Jegan/Rathiya/blob/Rathiya-Jegan-branch-1/Rathiya_coding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_oQ2zIdOvvn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform thresholding segmentation and calculate metrics\n",
        "def thresholding_segmentation_and_metrics(image_path, ground_truth_path, loss):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, segmented_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_mask)  # Display the segmented image in black and white\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Process validation data\n",
        "validation_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "\n",
        "        # Load the corresponding loss value for this image\n",
        "        # Replace the following line with code to load the actual loss value\n",
        "        loss = 0.1  # Placeholder, replace with actual code\n",
        "\n",
        "        metrics = thresholding_segmentation_and_metrics(image_path, ground_truth_path, loss)\n",
        "        if metrics is not None:\n",
        "            validation_metrics['Accuracy'].append(metrics[0])\n",
        "            validation_metrics['Precision'].append(metrics[1])\n",
        "            validation_metrics['Recall'].append(metrics[2])\n",
        "            validation_metrics['F-Score'].append(metrics[3])\n",
        "            validation_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Process testing data\n",
        "testing_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "\n",
        "        # Load the corresponding loss value for this image\n",
        "        # Replace the following line with code to load the actual loss value\n",
        "        loss = 0.1  # Placeholder, replace with actual code\n",
        "\n",
        "        metrics = thresholding_segmentation_and_metrics(image_path, ground_truth_path, loss)\n",
        "        if metrics is not None:\n",
        "            testing_metrics['Accuracy'].append(metrics[0])\n",
        "            testing_metrics['Precision'].append(metrics[1])\n",
        "            testing_metrics['Recall'].append(metrics[2])\n",
        "            testing_metrics['F-Score'].append(metrics[3])\n",
        "            testing_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Display the metrics for validation and testing\n",
        "print(\"Validation Metrics:\")\n",
        "print(\"Accuracy: {:.2f}%\".format(np.mean(validation_metrics['Accuracy'])))\n",
        "print(\"Precision: {:.2f}%\".format(np.mean(validation_metrics['Precision'])))\n",
        "print(\"Recall: {:.2f}%\".format(np.mean(validation_metrics['Recall'])))\n",
        "print(\"F-Score: {:.2f}%\".format(np.mean(validation_metrics['F-Score'])))\n",
        "print(\"Loss: {:.2f}\".format(np.mean(validation_metrics['Loss'])))\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(\"Accuracy: {:.2f}%\".format(np.mean(testing_metrics['Accuracy'])))\n",
        "print(\"Precision: {:.2f}%\".format(np.mean(testing_metrics['Precision'])))\n",
        "print(\"Recall: {:.2f}%\".format(np.mean(testing_metrics['Recall'])))\n",
        "print(\"F-Score: {:.2f}%\".format(np.mean(testing_metrics['F-Score'])))\n",
        "print(\"Loss: {:.2f}\".format(np.mean(testing_metrics['Loss'])))\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(validation_metrics['Accuracy'], label=\"Validation Accuracy\")\n",
        "plt.plot(testing_metrics['Accuracy'], label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(validation_metrics['F-Score'], label=\"Validation F-Score\")\n",
        "plt.plot(testing_metrics['F-Score'], label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(validation_metrics['Loss'], label=\"Validation Loss\")\n",
        "plt.plot(testing_metrics['Loss'], label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(validation_metrics['Precision'], label=\"Validation Precision\")\n",
        "plt.plot(testing_metrics['Precision'], label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(validation_metrics['Recall'], label=\"Validation Recall\")\n",
        "plt.plot(testing_metrics['Recall'], label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git -y\n"
      ],
      "metadata": {
        "id": "Odu_u9fiS_aA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jHPFkOgikSP"
      },
      "outputs": [],
      "source": [
        "!git config --global user.name \"Rathiya-Jegan\"\n",
        "!git config --global user.email \"vr.rathiya03@gmail.com\"\n",
        "!rm -rf Rathiya\n",
        "\n",
        "!git clone https://github.com/Rathiya-Jegan/Rathiya.git\n",
        "import os\n",
        "os.listdir()\n",
        "!cp rathiya_new_phd.ipynb Rathiya/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di_tqDMU6Fh4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def gaussian_blur(image, sigma=1):\n",
        "    return cv2.GaussianBlur(image, (0, 0), sigma)\n",
        "\n",
        "def kmeans_segmentation(image, k):\n",
        "    reshaped_image = image.reshape((-1, 3))\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(reshaped_image)\n",
        "    segmented_image = kmeans.labels_.reshape(image.shape[:2])\n",
        "    return segmented_image\n",
        "\n",
        "def extract_features(image):\n",
        "    # Implement feature extraction logic for MDSG-SE block\n",
        "    # ...\n",
        "\n",
        "def train_classifier(X_train, y_train):\n",
        "    classifier = SVC(kernel='linear')\n",
        "    classifier.fit(X_train, y_train)\n",
        "    return classifier\n",
        "\n",
        "def main(folder_path):\n",
        "    # Load images from the specified folder\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        original_image = cv2.imread(image_path)\n",
        "\n",
        "        # Apply Gaussian blur pre-processing\n",
        "        blurred_image = gaussian_blur(original_image)\n",
        "\n",
        "        # Apply K-means segmentation\n",
        "        k = 3  # You can adjust the number of clusters as needed\n",
        "        segmented_image = kmeans_segmentation(blurred_image, k)\n",
        "\n",
        "        # Extract features using MDSG-SE block\n",
        "        features = extract_features(segmented_image)\n",
        "\n",
        "        # Append the features and corresponding label\n",
        "        X.append(features)\n",
        "        y.append(label)  # Assign the appropriate label\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier = train_classifier(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    folder_path = input(\"Enter the folder path containing images: \")\n",
        "    main(folder_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPKSxLMFP17B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiI11v3C-I76"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F23cnVF63KD0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual code)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}%\")\n",
        "    print(f\"Recall: {recall:.2f}%\")\n",
        "    print(f\"F-Score: {f_score:.2f}%\")\n",
        "    print(f\"Loss: {loss:.2f}\")  # Print the loss value\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Process validation data\n",
        "validation_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        metrics = watershed_segmentation_and_metrics(image_path, ground_truth_path)\n",
        "        if metrics is not None:\n",
        "            validation_metrics['Accuracy'].append(metrics[0])\n",
        "            validation_metrics['Precision'].append(metrics[1])\n",
        "            validation_metrics['Recall'].append(metrics[2])\n",
        "            validation_metrics['F-Score'].append(metrics[3])\n",
        "            validation_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Process testing data\n",
        "testing_metrics = {'Accuracy': [], 'Precision': [], 'Recall': [], 'F-Score': [], 'Loss': []}\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        metrics = watershed_segmentation_and_metrics(image_path, ground_truth_path)\n",
        "        if metrics is not None:\n",
        "            testing_metrics['Accuracy'].append(metrics[0])\n",
        "            testing_metrics['Precision'].append(metrics[1])\n",
        "            testing_metrics['Recall'].append(metrics[2])\n",
        "            testing_metrics['F-Score'].append(metrics[3])\n",
        "            testing_metrics['Loss'].append(metrics[4])\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(validation_metrics['Accuracy'], label=\"Validation Accuracy\")\n",
        "plt.plot(testing_metrics['Accuracy'], label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(validation_metrics['F-Score'], label=\"Validation F-Score\")\n",
        "plt.plot(testing_metrics['F-Score'], label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(validation_metrics['Loss'], label=\"Validation Loss\")\n",
        "plt.plot(testing_metrics['Loss'], label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(validation_metrics['Precision'], label=\"Validation Precision\")\n",
        "plt.plot(testing_metrics['Precision'], label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(validation_metrics['Recall'], label=\"Validation Recall\")\n",
        "plt.plot(testing_metrics['Recall'], label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yngkY82F6LXc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5vCrdkL63Pd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Lists to store individual image metrics\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "\n",
        "    # Display the original and segmented images (commented out for faster execution)\n",
        "    # cv2_imshow(image)\n",
        "    # cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(val_accuracy_list, label=\"Validation Accuracy\")\n",
        "plt.plot(test_accuracy_list, label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(val_fscore_list, label=\"Validation F-Score\")\n",
        "plt.plot(test_fscore_list, label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
        "plt.plot(test_loss_list, label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(val_precision_list, label=\"Validation Precision\")\n",
        "plt.plot(test_precision_list, label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(val_recall_list, label=\"Validation Recall\")\n",
        "plt.plot(test_recall_list, label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkKQ2gnw_Oku"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 1 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "\n",
        "# Print metrics\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    avg_validating_precision = sum(validating_precisions) / len(validating_precisions)\n",
        "    avg_validating_recall = sum(validating_recalls) / len(validating_recalls)\n",
        "    avg_validating_f_score = sum(validating_f_scores) / len(validating_f_scores)\n",
        "    avg_validating_loss = sum(validating_losses) / len(validating_losses)\n",
        "\n",
        "    print(f\"Validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "    print(f\"Validation Data Precision: {avg_validating_precision:.2f}\")\n",
        "    print(f\"Validation Data Recall: {avg_validating_recall:.2f}\")\n",
        "    print(f\"Validation Data F-Score: {avg_validating_f_score:.2f}\")\n",
        "    print(f\"Validation Data Loss: {avg_validating_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No validation data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    avg_testing_precision = sum(testing_precisions) / len(testing_precisions)\n",
        "    avg_testing_recall = sum(testing_recalls) / len(testing_recalls)\n",
        "    avg_testing_f_score = sum(testing_f_scores) / len(testing_f_scores)\n",
        "    avg_testing_loss = sum(testing_losses) / len(testing_losses)\n",
        "\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "    print(f\"Testing Data Precision: {avg_testing_precision:.2f}\")\n",
        "    print(f\"Testing Data Recall: {avg_testing_recall:.2f}\")\n",
        "    print(f\"Testing Data F-Score: {avg_testing_f_score:.2f}\")\n",
        "    print(f\"Testing Data Loss: {avg_testing_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "# Plotting function\n",
        "def plot_metrics(validation_metrics, testing_metrics, metric_name):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(validation_metrics, label='Validation', marker='o')\n",
        "    plt.plot(testing_metrics, label='Testing', marker='x')\n",
        "    plt.xlabel('Image Index')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend()\n",
        "    plt.title(f'Validation vs Testing {metric_name}')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the metrics\n",
        "if validating_accuracies and testing_accuracies:\n",
        "    plot_metrics(validating_accuracies, testing_accuracies, 'Accuracy')\n",
        "\n",
        "if validating_recalls and testing_recalls:\n",
        "    plot_metrics(validating_recalls, testing_recalls, 'Recall')\n",
        "\n",
        "if validating_f_scores and testing_f_scores:\n",
        "    plot_metrics(validating_f_scores, testing_f_scores, 'F-Score')\n",
        "\n",
        "if validating_losses and testing_losses:\n",
        "    plot_metrics(validating_losses, testing_losses, 'Loss')\n",
        "\n",
        "if validating_precisions and testing_precisions:\n",
        "    plot_metrics(validating_precisions, testing_precisions, 'Precision')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7koFCdv-4YZ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf spot'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf spot'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA5Up2WgiaFh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_7rHoZ1jo37q"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image from your Colab environment\n",
        "image_path = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl new/leaf curl30.jpg'  # Replace with the path to your image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Apply Gaussian blur\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Convert the Gaussian blurred image to grayscale\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the grayscale Gaussian blurred image\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(gaussian_blur_gray, cmap='gray')  # Specify the colormap as 'gray'\n",
        "#plt.title('Gaussian Blur (Grayscale)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywzOm-ul_sN6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "#train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl new'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "val_data_directory='/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "#training_accuracies = []\n",
        "#for filename in os.listdir(train_data_directory):\n",
        " #   if filename.endswith('.jpg'):\n",
        " #       image_path = os.path.join(train_data_directory, filename)\n",
        " #       ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        " #       accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        " #       if accuracy is not None:\n",
        " #           training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "   if filename.endswith('.jpg'):\n",
        "      image_path = os.path.join(val_data_directory, filename)\n",
        "      ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "      accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "      if accuracy is not None:\n",
        "          validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "#if training_accuracies:\n",
        "   # avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    #print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "#else:\n",
        " #   print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1s-6nDcLENr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "#train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "# Function to perform thresholding segmentation and calculate accuracy\n",
        "def thresholding_segmentation_and_accuracy(image_path, ground_truth_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, segmented_mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_mask)  # Display the segmented image in black and white\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "#training_accuracies = []\n",
        "#for filename in os.listdir(train_data_directory):\n",
        " #   if filename.endswith('.jpg'):\n",
        "     #   image_path = os.path.join(train_data_directory, filename)\n",
        "    #   ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "      #  accuracy = thresholding_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "      #  if accuracy is not None:\n",
        "        #    training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = thresholding_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = thresholding_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "# Calculate and print average accuracies\n",
        "#if training_accuracies:\n",
        " #   avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "   # print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "#else:\n",
        "   # print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validating Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IK7gUCahNtD9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/leaf curl'\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/leaf curl'\n",
        "\n",
        "# Function to perform watershed segmentation and calculate accuracy\n",
        "def watershed_segmentation_and_accuracy(image_path, ground_truth_path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "#training_accuracies = []\n",
        "#for filename in os.listdir(train_data_directory):\n",
        "    #if filename.endswith('.jpg'):\n",
        "        #image_path = os.path.join(train_data_directory, filename)\n",
        "        #ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        #accuracy = watershed_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        #if accuracy is not None:\n",
        "            #training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = watershed_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = watershed_segmentation_and_accuracy(image_path, ground_truth_path)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "# Calculate and print average accuracies\n",
        "#if training_accuracies:\n",
        "    #avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    #print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "#else:\n",
        "    #print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validating Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE9SfcNjE29J"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf curl'\n",
        "val_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/val/leaf curl'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validating Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eonG4yqHASql"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psu0VywGAe9T"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/whitefly'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/whitefly'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/whitefly'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVfi-PWDBfiK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/whitefly'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/whitefly'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/whitefly'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDJ2QaEEB_KD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/yellowish'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=10)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in3yFioYDmPN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-uEki98bDmiu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/yellowish'\n",
        "val_data_directory='/content/drive/MyDrive/Chili_Plant_Disease/val/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# process validating data\n",
        "validating_accuracies = []\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    print(f\"validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "\n",
        "else:\n",
        "    print(\"No validating data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O__fI7j2-O7C"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255)\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 1 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss\n",
        "\n",
        "# Function to display the original image, segmented image, and Gaussian blurred image\n",
        "def display_images(image, segmented_image, gaussian_blur_gray):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Segmented Image\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Segmented Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Gaussian Blurred Image (Grayscale)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(gaussian_blur_gray, cmap='gray')\n",
        "    plt.title('Gaussian Blur (Grayscale)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "\n",
        "# Print metrics\n",
        "if validating_accuracies:\n",
        "    avg_validating_accuracy = sum(validating_accuracies) / len(validating_accuracies)\n",
        "    avg_validating_precision = sum(validating_precisions) / len(validating_precisions)\n",
        "    avg_validating_recall = sum(validating_recalls) / len(validating_recalls)\n",
        "    avg_validating_f_score = sum(validating_f_scores) / len(validating_f_scores)\n",
        "    avg_validating_loss = sum(validating_losses) / len(validating_losses)\n",
        "\n",
        "    print(f\"Validation Data Accuracy: {avg_validating_accuracy:.2f}%\")\n",
        "    print(f\"Validation Data Precision: {avg_validating_precision:.2f}\")\n",
        "    print(f\"Validation Data Recall: {avg_validating_recall:.2f}\")\n",
        "    print(f\"Validation Data F-Score: {avg_validating_f_score:.2f}\")\n",
        "    print(f\"Validation Data Loss: {avg_validating_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No validation data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    avg_testing_precision = sum(testing_precisions) / len(testing_precisions)\n",
        "    avg_testing_recall = sum(testing_recalls) / len(testing_recalls)\n",
        "    avg_testing_f_score = sum(testing_f_scores) / len(testing_f_scores)\n",
        "    avg_testing_loss = sum(testing_losses) / len(testing_losses)\n",
        "\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "    print(f\"Testing Data Precision: {avg_testing_precision:.2f}\")\n",
        "    print(f\"Testing Data Recall: {avg_testing_recall:.2f}\")\n",
        "    print(f\"Testing Data F-Score: {avg_testing_f_score:.2f}\")\n",
        "    print(f\"Testing Data Loss: {avg_testing_loss:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n",
        "\n",
        "# Plotting function\n",
        "def plot_metrics(validation_metrics, testing_metrics, metric_name):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(validation_metrics, label='Validation', marker='o')\n",
        "    plt.plot(testing_metrics, label='Testing', marker='x')\n",
        "    plt.xlabel('Image Index')\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.legend()\n",
        "    plt.title(f'Validation vs Testing {metric_name}')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the metrics\n",
        "if validating_accuracies and testing_accuracies:\n",
        "    plot_metrics(validating_accuracies, testing_accuracies, 'Accuracy')\n",
        "\n",
        "if validating_recalls and testing_recalls:\n",
        "    plot_metrics(validating_recalls, testing_recalls, 'Recall')\n",
        "\n",
        "if validating_f_scores and testing_f_scores:\n",
        "    plot_metrics(validating_f_scores, testing_f_scores, 'F-Score')\n",
        "\n",
        "if validating_losses and testing_losses:\n",
        "    plot_metrics(validating_losses, testing_losses, 'Loss')\n",
        "\n",
        "if validating_precisions and testing_precisions:\n",
        "    plot_metrics(validating_precisions, testing_precisions, 'Precision')\n",
        "\n",
        "# Load an image from your Colab environment for Gaussian Blur pre-processing\n",
        "image_path = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf curl new/leaf curl90.jpg'  # Replace with your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Apply Gaussian blur\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Convert the Gaussian blurred image to grayscale\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the grayscale Gaussian blurred image\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(gaussian_blur_gray, cmap='gray')  # Specify the colormap as 'gray'\n",
        "plt.title('Gaussian Blur (Grayscale)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the original image, segmented image, and Gaussian-blurred image for a specific image\n",
        "sample_image_path = '/content/drive/MyDrive/preprocessed/val/yellowish/sample.jpg'  # Replace with your image path\n",
        "sample_ground_truth_path = '/content/drive/MyDrive/preprocessed/val/yellowish/sample_mask.png'  # Replace with ground truth path\n",
        "\n",
        "image = cv2.imread(sample_image_path)\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "accuracy, _, _, _, _ = kmeans_segmentation_and_metrics(sample_image_path, sample_ground_truth_path, num_clusters=2)\n",
        "\n",
        "if accuracy is not None:\n",
        "    display_images(image, segmented_image, gaussian_blur_gray)\n",
        "else:\n",
        "    print(\"Image segmentation failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X4yTc3RtfV6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Lists to store individual image metrics\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "\n",
        "    # Display the original and segmented images (commented out for faster execution)\n",
        "    # cv2_imshow(image)\n",
        "    # cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n",
        "\n",
        "# Create line graphs for metrics\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Validation vs Testing Accuracy\n",
        "plt.subplot(2, 3, 1)\n",
        "plt.plot(val_accuracy_list, label=\"Validation Accuracy\")\n",
        "plt.plot(test_accuracy_list, label=\"Testing Accuracy\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Validation vs Testing Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing F-Score\n",
        "plt.subplot(2, 3, 2)\n",
        "plt.plot(val_fscore_list, label=\"Validation F-Score\")\n",
        "plt.plot(test_fscore_list, label=\"Testing F-Score\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"F-Score (%)\")\n",
        "plt.title(\"Validation vs Testing F-Score\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Loss\n",
        "plt.subplot(2, 3, 3)\n",
        "plt.plot(val_loss_list, label=\"Validation Loss\")\n",
        "plt.plot(test_loss_list, label=\"Testing Loss\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation vs Testing Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Precision\n",
        "plt.subplot(2, 3, 4)\n",
        "plt.plot(val_precision_list, label=\"Validation Precision\")\n",
        "plt.plot(test_precision_list, label=\"Testing Precision\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Precision (%)\")\n",
        "plt.title(\"Validation vs Testing Precision\")\n",
        "plt.legend()\n",
        "\n",
        "# Validation vs Testing Recall\n",
        "plt.subplot(2, 3, 5)\n",
        "plt.plot(val_recall_list, label=\"Validation Recall\")\n",
        "plt.plot(test_recall_list, label=\"Testing Recall\")\n",
        "plt.xlabel(\"Images\")\n",
        "plt.ylabel(\"Recall (%)\")\n",
        "plt.title(\"Validation vs Testing Recall\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKTB4dz8u-Ml"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Lists to store individual image metrics and segmented images\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "val_segmented_images = []  # Store segmented images\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "test_segmented_images = []  # Store segmented images\n",
        "\n",
        "# Function to display images (original and segmented)\n",
        "def display_images(original, segmented):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Original Image\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(\"Segmented Image\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "        val_segmented_images.append(segmented_image)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "        test_segmented_images.append(segmented_image)\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    display_images(image, segmented_image)\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-sWniFnxmib"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Lists to store individual image metrics and segmented images\n",
        "val_accuracy_list = []\n",
        "val_precision_list = []\n",
        "val_recall_list = []\n",
        "val_fscore_list = []\n",
        "val_loss_list = []\n",
        "val_segmented_images = []  # Store segmented images\n",
        "\n",
        "test_accuracy_list = []\n",
        "test_precision_list = []\n",
        "test_recall_list = []\n",
        "test_fscore_list = []\n",
        "test_loss_list = []\n",
        "test_segmented_images = []  # Store segmented images\n",
        "\n",
        "# Function to display images (original and segmented)\n",
        "def display_images(original, segmented):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    #plt.subplot(1, 2, 1)\n",
        "    #plt.imshow(cv2.cvtColor(original, cv2.COLOR_BGR2RGB))\n",
        "    #plt.title(\"Original Image\")\n",
        "    #plt.axis('off')  # Remove axis\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(cv2.cvtColor(segmented, cv2.COLOR_BGR2RGB))\n",
        "    #plt.title(\"Segmented Image\")\n",
        "    plt.axis('off')  # Remove axis\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Function to perform watershed segmentation and calculate metrics\n",
        "def watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to create a binary image\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Perform morphological operations to remove noise and improve segmentation\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    # Find sure foreground area using distance transform\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    # Subtract sure foreground from sure background to get the unknown region\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Label the markers for watershed\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    # Apply watershed algorithm\n",
        "    cv2.watershed(image, markers)\n",
        "    segmented_image = image.copy()\n",
        "    segmented_image[markers == -1] = [0, 0, 255]  # Mark the boundaries with red color\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 1, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    # You need to calculate the loss here and assign it to the 'loss' variable.\n",
        "\n",
        "    # Sample loss calculation (you need to replace this with actual loss calculation)\n",
        "    loss = 0.5  # Replace with actual loss calculation\n",
        "\n",
        "    if is_validation:\n",
        "        # Append metrics to validation lists\n",
        "        val_accuracy_list.append(accuracy)\n",
        "        val_precision_list.append(precision)\n",
        "        val_recall_list.append(recall)\n",
        "        val_fscore_list.append(f_score)\n",
        "        val_loss_list.append(loss)\n",
        "        val_segmented_images.append(segmented_image)\n",
        "    else:\n",
        "        # Append metrics to testing lists\n",
        "        test_accuracy_list.append(accuracy)\n",
        "        test_precision_list.append(precision)\n",
        "        test_recall_list.append(recall)\n",
        "        test_fscore_list.append(f_score)\n",
        "        test_loss_list.append(loss)\n",
        "        test_segmented_images.append(segmented_image)\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    display_images(image, segmented_image)\n",
        "\n",
        "# Process validation data\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=True)\n",
        "\n",
        "# Process testing data\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        watershed_segmentation_and_metrics(image_path, ground_truth_path, is_validation=False)\n",
        "\n",
        "# Calculate average metrics\n",
        "val_avg_accuracy = sum(val_accuracy_list) / len(val_accuracy_list)\n",
        "val_avg_precision = sum(val_precision_list) / len(val_precision_list)\n",
        "val_avg_recall = sum(val_recall_list) / len(val_recall_list)\n",
        "val_avg_fscore = sum(val_fscore_list) / len(val_fscore_list)\n",
        "val_avg_loss = sum(val_loss_list) / len(val_loss_list)\n",
        "\n",
        "test_avg_accuracy = sum(test_accuracy_list) / len(test_accuracy_list)\n",
        "test_avg_precision = sum(test_precision_list) / len(test_precision_list)\n",
        "test_avg_recall = sum(test_recall_list) / len(test_recall_list)\n",
        "test_avg_fscore = sum(test_fscore_list) / len(test_fscore_list)\n",
        "test_avg_loss = sum(test_loss_list) / len(test_loss_list)\n",
        "\n",
        "# Display the metrics\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {val_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {val_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {val_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {val_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {val_avg_loss:.2f}\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {test_avg_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {test_avg_precision:.2f}%\")\n",
        "print(f\"Average Recall: {test_avg_recall:.2f}%\")\n",
        "print(f\"Average F-Score: {test_avg_fscore:.2f}%\")\n",
        "print(f\"Average Loss: {test_avg_loss:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVDM6yLb4PaY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/train/leaf curl'\n",
        "test_data_directory = '/content/drive/MyDrive/Chili_Plant_Disease/test/leaf curl'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n",
        "\n",
        "if testing_accuracies:\n",
        "    avg_testing_accuracy = sum(testing_accuracies) / len(testing_accuracies)\n",
        "    print(f\"Testing Data Accuracy: {avg_testing_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No testing data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3npF8vU63qW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 100 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss, segmented_image\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "validating_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "            validating_segmented_images.append(segmented_image)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "testing_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "            testing_segmented_images.append(segmented_image)\n",
        "\n",
        "# Create separate line graphs for comparing metrics\n",
        "metrics_labels = ['Accuracy', 'Precision', 'Recall', 'F-Score', 'Loss']\n",
        "\n",
        "# Validation vs. Testing Recall\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_recalls, label='Validation Recall', marker='o', linestyle='-')\n",
        "plt.plot(testing_recalls, label='Testing Recall', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Recall (%)')\n",
        "plt.title('Validation vs. Testing Recall Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_recalls)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing F-Score\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_f_scores, label='Validation F-Score', marker='o', linestyle='-')\n",
        "plt.plot(testing_f_scores, label='Testing F-Score', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('F-Score (%)')\n",
        "plt.title('Validation vs. Testing F-Score Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_f_scores)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing Precision\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_precisions, label='Validation Precision', marker='o', linestyle='-')\n",
        "plt.plot(testing_precisions, label='Testing Precision', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Precision (%)')\n",
        "plt.title('Validation vs. Testing Precision Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_precisions)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing Accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_accuracies, label='Validation Accuracy', marker='o', linestyle='-')\n",
        "plt.plot(testing_accuracies, label='Testing Accuracy', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Validation vs. Testing Accuracy Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_accuracies)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Validation vs. Testing Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(validating_losses, label='Validation Loss', marker='o', linestyle='-')\n",
        "plt.plot(testing_losses, label='Testing Loss', marker='o', linestyle='-')\n",
        "plt.xlabel('Images')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation vs. Testing Loss Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(range(len(validating_losses)))  # Assuming the number of images is the same for both validation and testing\n",
        "plt.show()\n",
        "\n",
        "# Display some segmented images\n",
        "num_images_to_display = 5\n",
        "for i in range(min(num_images_to_display, len(validating_segmented_images))):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(validating_segmented_images[i], cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Segmented Image {i+1}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRxaePDR9-q9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/healthy'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/healthy'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 100 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss, segmented_image\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "validating_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "            validating_segmented_images.append(segmented_image)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "testing_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "            testing_segmented_images.append(segmented_image)\n",
        "\n",
        "# Display all segmented images\n",
        "for i, segmented_image in enumerate(validating_segmented_images):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Segmented Image {i+1}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display metrics in percentage values\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(validating_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(validating_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(validating_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(validating_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(validating_losses):.2f}%\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(testing_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(testing_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(testing_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(testing_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(testing_losses):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIU-SHUPBF5D"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories for training and testing data\n",
        "val_data_directory = '/content/drive/MyDrive/preprocessed/val/yellowish'\n",
        "test_data_directory = '/content/drive/MyDrive/preprocessed/test/yellowish'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy, precision, recall, F-score, and loss\n",
        "def kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate precision, recall, and F-score\n",
        "    precision = precision_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    recall = recall_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "    f_score = f1_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Calculate loss (1 - F-score)\n",
        "    loss = 100 - f_score\n",
        "\n",
        "    return accuracy, precision, recall, f_score, loss, segmented_image\n",
        "\n",
        "# Process training data\n",
        "validating_accuracies = []\n",
        "validating_precisions = []\n",
        "validating_recalls = []\n",
        "validating_f_scores = []\n",
        "validating_losses = []\n",
        "validating_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(val_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(val_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(val_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            validating_accuracies.append(accuracy)\n",
        "            validating_precisions.append(precision)\n",
        "            validating_recalls.append(recall)\n",
        "            validating_f_scores.append(f_score)\n",
        "            validating_losses.append(loss)\n",
        "            validating_segmented_images.append(segmented_image)\n",
        "\n",
        "# Process testing data\n",
        "testing_accuracies = []\n",
        "testing_precisions = []\n",
        "testing_recalls = []\n",
        "testing_f_scores = []\n",
        "testing_losses = []\n",
        "testing_segmented_images = []\n",
        "\n",
        "for filename in os.listdir(test_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(test_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(test_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy, precision, recall, f_score, loss, segmented_image = kmeans_segmentation_and_metrics(image_path, ground_truth_path, num_clusters=2)\n",
        "        if accuracy is not None:\n",
        "            testing_accuracies.append(accuracy)\n",
        "            testing_precisions.append(precision)\n",
        "            testing_recalls.append(recall)\n",
        "            testing_f_scores.append(f_score)\n",
        "            testing_losses.append(loss)\n",
        "            testing_segmented_images.append(segmented_image)\n",
        "\n",
        "# Display all segmented images (Validation)\n",
        "for i, segmented_image in enumerate(validating_segmented_images):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Validation Segmented Image {i+1}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display all segmented images (Testing)\n",
        "for i, segmented_image in enumerate(testing_segmented_images):\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Testing Segmented Image {i+1}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display metrics in percentage values\n",
        "print(\"Validation Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(validating_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(validating_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(validating_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(validating_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(validating_losses):.2f}%\")\n",
        "\n",
        "print(\"\\nTesting Metrics:\")\n",
        "print(f\"Average Accuracy: {np.mean(testing_accuracies):.2f}%\")\n",
        "print(f\"Average Precision: {np.mean(testing_precisions):.2f}%\")\n",
        "print(f\"Average Recall: {np.mean(testing_recalls):.2f}%\")\n",
        "print(f\"Average F-Score: {np.mean(testing_f_scores):.2f}%\")\n",
        "print(f\"Average Loss: {np.mean(testing_losses):.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x44J3lmFBmh"
      },
      "outputs": [],
      "source": [
        "pip install opencv-python numpy deap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB4MYSUM2c5m"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/preprocessed/train/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSzN3lpu9EuC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load an image from your Colab environment\n",
        "image_path = '/content/drive/MyDrive/Chili_Plant_Disease/train/yellowish/yellowisha22.jpg'  # Replace with the path to your image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Apply Gaussian blur\n",
        "gaussian_blur = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "\n",
        "# Convert the Gaussian blurred image to grayscale\n",
        "gaussian_blur_gray = cv2.cvtColor(gaussian_blur, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Display the grayscale Gaussian blurred image\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.imshow(gaussian_blur_gray, cmap='gray')  # Specify the colormap as 'gray'\n",
        "#plt.title('Gaussian Blur (Grayscale)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzOJryPyB2p7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score (ground_truth.flatten() // 255,  segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    #cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuKtgFkWxDPm"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Define directories for training and testing data\n",
        "train_data_directory = '/content/drive/MyDrive/leaf spot'\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Ensure both images have the same dimensions\n",
        "    if image.shape[:2] != ground_truth.shape:\n",
        "        print(f\"Error: Image dimensions do not match ground truth dimensions. Check: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Resize the segmented mask to match ground truth dimensions\n",
        "    segmented_mask = cv2.resize(segmented_mask, (ground_truth.shape[1], ground_truth.shape[0]))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    # cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Process training data\n",
        "training_accuracies = []\n",
        "for filename in os.listdir(train_data_directory):\n",
        "    if filename.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_data_directory, filename)\n",
        "        ground_truth_path = os.path.join(train_data_directory, filename.replace('.jpg', '_mask.png'))\n",
        "        accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters=4)\n",
        "        if accuracy is not None:\n",
        "            training_accuracies.append(accuracy)\n",
        "\n",
        "# Calculate and print average accuracies\n",
        "if training_accuracies:\n",
        "    avg_training_accuracy = sum(training_accuracies) / len(training_accuracies)\n",
        "    print(f\"Training Data Accuracy: {avg_training_accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"No training data processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERlbgL_73sCn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab.patches import cv2_imshow  # Import cv2_imshow\n",
        "\n",
        "# Function to perform K-means segmentation and calculate accuracy\n",
        "def kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Load the ground truth mask\n",
        "    ground_truth = cv2.imread(ground_truth_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if image is None or ground_truth is None:\n",
        "        print(f\"Error: Image or ground truth not loaded. Check paths: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Ensure both images have the same dimensions\n",
        "    if image.shape[:2] != ground_truth.shape:\n",
        "        print(f\"Error: Image dimensions do not match ground truth dimensions. Check: {image_path}, {ground_truth_path}\")\n",
        "        return None\n",
        "\n",
        "    # Perform K-means clustering on the image\n",
        "    reshaped_image = image.reshape(-1, 3)\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(reshaped_image)\n",
        "    segmented_image = kmeans.cluster_centers_[kmeans.labels_].reshape(image.shape).astype(np.uint8)\n",
        "\n",
        "    # Convert segmented image to grayscale\n",
        "    segmented_gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Convert segmented image to binary mask\n",
        "    _, segmented_mask = cv2.threshold(segmented_gray, 128, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Resize the segmented mask to match ground truth dimensions\n",
        "    segmented_mask = cv2.resize(segmented_mask, (ground_truth.shape[1], ground_truth.shape[0]))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(ground_truth.flatten() // 255, segmented_mask.flatten() // 255) * 100\n",
        "\n",
        "    # Display the original and segmented images\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(segmented_gray)  # Display the segmented image in grayscale\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# Path to your single image and its corresponding ground truth mask\n",
        "image_path = '/content/drive/MyDrive/leaf spot/59.jpg'\n",
        "#ground_truth_path = '/content/drive/MyDrive/leaf spot/59_mask.png'\n",
        "\n",
        "# Number of clusters for K-means\n",
        "num_clusters = 4\n",
        "\n",
        "# Call the function with the single image\n",
        "accuracy = kmeans_segmentation_and_accuracy(image_path, ground_truth_path, num_clusters)\n",
        "\n",
        "if accuracy is not None:\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "else:\n",
        "    print(\"Image processing failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpIVsvPCkxac"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nzrDHn3w99A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier (Multinomial Naive Bayes for image data)\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Had70CvpxqRF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apoRaGE9yclb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Logistic Regression classifier\n",
        "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WZGK62Tz5Jb"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-fuzzy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UefnqOC1Kxn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Create the neural network model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(100, 100)),  # Flatten the 2D image to a 1D vector\n",
        "    keras.layers.Dense(128, activation='relu'),    # Fully connected layer with 128 units and ReLU activation\n",
        "    keras.layers.Dense(10, activation='softmax')   # Output layer with 10 units (assuming 10 classes) and softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Step 4: Train the neural network\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 5: Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Step 6: Make predictions and generate a classification report\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HflQCtD-YxNZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to load and preprocess data\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Function to create and train the neural network model\n",
        "def train_neural_network(X_train, y_train, num_epochs=10, batch_size=32):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Flatten(input_shape=(100, 100)),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "# Number of runs and storage for accuracy values\n",
        "num_runs = 10\n",
        "accuracies = []\n",
        "\n",
        "for run in range(num_runs):\n",
        "    print(f\"Run {run + 1}/{num_runs}\")\n",
        "    images, labels = load_and_preprocess_data(data_directory)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_neural_network(X_train, y_train)\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    accuracies.append(test_accuracy)\n",
        "\n",
        "# Plot the accuracy line graph\n",
        "plt.plot(range(1, num_runs + 1), accuracies, marker='o', linestyle='-')\n",
        "plt.xlabel('Run')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Test Accuracy vs. Run')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5LKW6aTa0p0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import skfuzzy as fuzz\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (subdirectories for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Define fuzzy logic rules (simplified example)\n",
        "def fuzzy_logic_classifier(input_data):\n",
        "    # Define membership functions for input data\n",
        "    input_membership = fuzz.trimf(input_data, [0, 0, 255])\n",
        "\n",
        "    # Define fuzzy rules (simplified)\n",
        "    # Rule 1: If input_data is low, then output is \"Not Likely\"\n",
        "    # Rule 2: If input_data is high, then output is \"Highly Likely\"\n",
        "    output_membership = np.zeros_like(input_data)\n",
        "    output_membership[input_data > 128] = 1\n",
        "\n",
        "    return output_membership\n",
        "\n",
        "# Step 4: Apply fuzzy logic to classify images and store the fuzzy outputs\n",
        "fuzzy_outputs = [fuzzy_logic_classifier(image.flatten()) for image in X_test]\n",
        "\n",
        "# Step 5: Visualize fuzzy outputs for a few test images\n",
        "num_images_to_visualize = 100\n",
        "\n",
        "for i in range(num_images_to_visualize):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    # Input image\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow (X_test[i], cmap='gray')\n",
        "    plt.title('Input Image')\n",
        "\n",
        "    # Fuzzy outputs\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(fuzzy_outputs[i])\n",
        "    plt.title('Fuzzy Outputs')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Step 6: Convert fuzzy outputs to crisp labels (e.g., using defuzzification)\n",
        "\n",
        "# Step 7: Evaluate the classifier (crisp labels) as in your previous code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEp5n0tHBf_d"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the segmented image\n",
        "segmented_image = cv2.imread('/content/drive/MyDrive/Kmeans/healthy/test/1.jpg')\n",
        "\n",
        "# Convert the segmented image to the HSV color space (optional but often used for color analysis)\n",
        "hsv_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define the number of bins for the histogram\n",
        "num_bins = 256  # You can adjust this value as needed\n",
        "\n",
        "# Compute the histogram for each channel (Hue, Saturation, and Value)\n",
        "hist_hue = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 256])\n",
        "hist_saturation = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])\n",
        "hist_value = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(131)\n",
        "plt.plot(hist_hue, color='b')\n",
        "plt.title('Hue Histogram')\n",
        "plt.subplot(132)\n",
        "plt.plot(hist_saturation, color='g')\n",
        "plt.title('Saturation Histogram')\n",
        "plt.subplot(133)\n",
        "plt.plot(hist_value, color='r')\n",
        "plt.title('Value Histogram')\n",
        "plt.xlim([0, 256])\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4rTjIOtB9kf"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the segmented image\n",
        "segmented_image = cv2.imread('/content/drive/MyDrive/Kmeans/healthy/test/11.jpg')\n",
        "\n",
        "# Convert the segmented image to the HSV color space\n",
        "hsv_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define the number of bins for the histogram\n",
        "num_bins = 256\n",
        "\n",
        "# Compute the histogram for each channel (Hue, Saturation, and Value)\n",
        "hist_hue = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 256])\n",
        "hist_saturation = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])\n",
        "hist_value = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(131)\n",
        "plt.plot(hist_hue, color='b')\n",
        "plt.title('Hue Histogram')\n",
        "plt.subplot(132)\n",
        "plt.plot(hist_saturation, color='g')\n",
        "plt.title('Saturation Histogram')\n",
        "plt.subplot(133)\n",
        "plt.plot(hist_value, color='r')\n",
        "plt.title('Value Histogram')\n",
        "plt.xlim([0, 256])\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the segmented image\n",
        "plt.figure()\n",
        "plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Segmented Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80fxJHGVEK5g"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrJZ4I-eELxz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the segmented image\n",
        "segmented_image = cv2.imread('/content/drive/MyDrive/Kmeans/healthy/test/11.jpg')\n",
        "\n",
        "# Convert the segmented image to the HSV color space\n",
        "hsv_image = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "# Define the number of bins for the histogram\n",
        "num_bins = 256\n",
        "\n",
        "# Compute the histogram for each channel (Hue, Saturation, and Value)\n",
        "hist_hue = cv2.calcHist([hsv_image], [0], None, [num_bins], [0, 256])\n",
        "hist_saturation = cv2.calcHist([hsv_image], [1], None, [num_bins], [0, 256])\n",
        "hist_value = cv2.calcHist([hsv_image], [2], None, [num_bins], [0, 256])\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(131)\n",
        "plt.plot(hist_hue, color='b')\n",
        "plt.title('Hue Histogram')\n",
        "plt.subplot(132)\n",
        "plt.plot(hist_saturation, color='g')\n",
        "plt.title('Saturation Histogram')\n",
        "plt.subplot(133)\n",
        "plt.plot(hist_value, color='r')\n",
        "plt.title('Value Histogram')\n",
        "plt.xlim([0, 256])\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Display the segmented image\n",
        "plt.figure()\n",
        "plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Segmented Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3by05sgaZeK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Directory containing segmented images\n",
        "segmented_dir = '/content/drive/MyDrive/Kmeans/yellowish/train'\n",
        "\n",
        "# Initialize lists to store shape features\n",
        "areas = []\n",
        "perimeters = []\n",
        "circularities = []\n",
        "\n",
        "# Loop through segmented images\n",
        "for filename in os.listdir(segmented_dir):\n",
        "    if filename.endswith('.jpg'):\n",
        "        # Load segmented image\n",
        "        segmented_image = cv2.imread(os.path.join(segmented_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Find contours in the segmented image\n",
        "        contours, _ = cv2.findContours(segmented_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Initialize variables to store shape features for this image\n",
        "        area = 0\n",
        "        perimeter = 0\n",
        "        circularity = 0\n",
        "\n",
        "        # Calculate shape features for each contour (assuming only one object per image)\n",
        "        if contours:\n",
        "            contour = contours[0]\n",
        "            area = cv2.contourArea(contour)\n",
        "            perimeter = cv2.arcLength(contour, True)\n",
        "            circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "        # Append shape features to the respective lists\n",
        "        areas.append(area)\n",
        "        perimeters.append(perimeter)\n",
        "        circularities.append(circularity)\n",
        "\n",
        "# Convert shape features to NumPy arrays\n",
        "areas = np.array(areas)\n",
        "perimeters = np.array(perimeters)\n",
        "circularities = np.array(circularities)\n",
        "\n",
        "# Print or use the extracted shape features as needed\n",
        "print(f\"Number of images processed: {len(areas)}\")\n",
        "print(f\"Mean Area: {np.mean(areas)}\")\n",
        "print(f\"Mean Perimeter: {np.mean(perimeters)}\")\n",
        "print(f\"Mean Circularity: {np.mean(circularities)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL07VZJlqwuQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sln89iYIrMot"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset with shape feature extraction\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    areas = []\n",
        "    perimeters = []\n",
        "    circularities = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                # Shape feature extraction\n",
        "                contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                area = 0\n",
        "                perimeter = 0\n",
        "                circularity = 0\n",
        "\n",
        "                if contours:\n",
        "                    contour = contours[0]\n",
        "                    area = cv2.contourArea(contour)\n",
        "                    perimeter = cv2.arcLength(contour, True)\n",
        "                    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                areas.append(area)\n",
        "                perimeters.append(perimeter)\n",
        "                circularities.append(circularity)\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(areas), np.array(perimeters), np.array(circularities)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels, areas, perimeters, circularities = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Combine shape features with flattened image pixels\n",
        "combined_features = np.column_stack((images.reshape(len(images), -1), areas, perimeters, circularities))\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjA4muAnrh0k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset with shape feature extraction\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    areas = []\n",
        "    perimeters = []\n",
        "    circularities = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                # Shape feature extraction\n",
        "                contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                area = 0\n",
        "                perimeter = 0\n",
        "                circularity = 0\n",
        "\n",
        "                if contours:\n",
        "                    contour = contours[0]\n",
        "                    area = cv2.contourArea(contour)\n",
        "                    perimeter = cv2.arcLength(contour, True)\n",
        "                    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "                # Append shape features to the respective lists\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                areas.append(area)\n",
        "                perimeters.append(perimeter)\n",
        "                circularities.append(circularity)\n",
        "\n",
        "                # Display area, perimeter, and circularity for this image\n",
        "                print(f\"Image: {filename}\")\n",
        "                print(f\"Area: {area}\")\n",
        "                print(f\"Perimeter: {perimeter}\")\n",
        "                print(f\"Circularity: {circularity}\\n\")\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(areas), np.array(perimeters), np.array(circularities)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels, areas, perimeters, circularities = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Combine shape features with flattened image pixels\n",
        "combined_features = np.column_stack((images.reshape(len(images), -1), areas, perimeters, circularities))\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLZWvXOnr8bY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset with shape feature extraction\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    areas = []\n",
        "    perimeters = []\n",
        "    circularities = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                # Shape feature extraction\n",
        "                contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "                area = 0\n",
        "                perimeter = 0\n",
        "                circularity = 0\n",
        "\n",
        "                if contours:\n",
        "                    contour = contours[0]\n",
        "                    area = cv2.contourArea(contour)\n",
        "                    perimeter = cv2.arcLength(contour, True)\n",
        "                    circularity = (4 * np.pi * area) / (perimeter ** 2)\n",
        "\n",
        "                # Append shape features to the respective lists\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "                areas.append(area)\n",
        "                perimeters.append(perimeter)\n",
        "                circularities.append(circularity)\n",
        "\n",
        "    return np.array(images), np.array(labels), np.array(areas), np.array(perimeters), np.array(circularities)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels, areas, perimeters, circularities = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Calculate the overall mean values for area, perimeter, and circularity\n",
        "overall_mean_area = np.mean(areas)\n",
        "overall_mean_perimeter = np.mean(perimeters)\n",
        "overall_mean_circularity = np.mean(circularities)\n",
        "\n",
        "print(\"Overall Mean Area:\", overall_mean_area)\n",
        "print(\"Overall Mean Perimeter:\", overall_mean_perimeter)\n",
        "print(\"Overall Mean Circularity:\", overall_mean_circularity)\n",
        "\n",
        "# Combine shape features with flattened image pixels\n",
        "combined_features = np.column_stack((images.reshape(len(images), -1), areas, perimeters, circularities))\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hnC_ITT0SnZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZLuGlG60pg8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVuvDJqN0pzW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf curl\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cjee1odT044F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqQfpvS005Nm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMpaSxhJ1Ix_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb7mjUGn1JFh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN1pOqHQ1VyC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJUIiDNR1WEf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the SVM classifier\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPHnnGxO26el"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78SWW4-R3SPe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKjGGOvb3jFX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z8IA_cz40Ck"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/healthy\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qK_zy3n48fg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf curl\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2COll-75DSC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/leaf spot\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmGXxfP05KcI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/white fly\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRO-Mxhe5iT6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the image dataset\n",
        "def load_and_preprocess_data(data_directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    class_names = os.listdir(data_directory)\n",
        "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(data_directory, class_name)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                label = class_dict[class_name]\n",
        "                image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Load image in grayscale\n",
        "                image = cv2.resize(image, (100, 100))  # Resize the image to a fixed size\n",
        "\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Specify the directory containing your dataset (two subdirectories, one for each class)\n",
        "data_directory = \"/content/drive/MyDrive/Kmeans/yellowish\"  # Update this path\n",
        "\n",
        "images, labels = load_and_preprocess_data(data_directory)\n",
        "\n",
        "# Step 2: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train.reshape(len(X_train), -1), y_train)\n",
        "\n",
        "# Step 4: Make predictions on the test set\n",
        "y_pred = clf.predict(X_test.reshape(len(X_test), -1))\n",
        "\n",
        "# Step 5: Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Step 6: Display 100 images from both training and test sets\n",
        "total_displayed = 100  # Change this to the number of images you want to display (max: 100)\n",
        "specific_image_indices = np.random.randint(0, len(images), total_displayed)\n",
        "\n",
        "for specific_image_index in specific_image_indices:\n",
        "    specific_image = images[specific_image_index]\n",
        "\n",
        "    predicted_label = clf.predict(specific_image.reshape(1, -1))[0]\n",
        "    actual_label = labels[specific_image_index]\n",
        "\n",
        "    # Convert labels back to class names (if you have class names)\n",
        "    class_names = {0: 'Class_0', 1: 'Class_1'}  # Replace with your class names\n",
        "    predicted_label = class_names[predicted_label]\n",
        "    actual_label = class_names[actual_label]\n",
        "\n",
        "    # Display the image along with labels\n",
        "    plt.imshow(specific_image, cmap='gray')\n",
        "    plt.title(f\"Predicted: {predicted_label}, Actual: {actual_label}\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phwtj9ZLgUAd"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvIhYrom4whv"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQu8OL9iEd6Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms-Sg8il7BYb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSNYK9n6ZQ8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Sample code for loading images and labels (modify according to your dataset structure)\n",
        "def load_data(img_folder, img_height, img_width):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(img_folder):\n",
        "        img = load_img(os.path.join(img_folder, filename), target_size=(img_height, img_width))\n",
        "        img_array = img_to_array(img)\n",
        "        images.append(img_array)\n",
        "        # Extract the label from the filename or use a predefined mapping\n",
        "        labels.append(extract_label_from_filename(filename))  # Implement a function to extract the label\n",
        "    return images, labels\n",
        "\n",
        "def extract_label_from_filename(filename):\n",
        "    # Implement your logic to extract the label from the filename\n",
        "    # For example, if filenames are like 'Healthy1.jpg' or 'Diseased2.jpg'\n",
        "    return filename.split('.')[0].lower()\n",
        "\n",
        "# Define the dimensions of your input images\n",
        "img_height, img_width, img_channels = 128, 128, 3  # Adjust these values based on your dataset\n",
        "\n",
        "img_folder = '/content/drive/MyDrive/segmentation/yellowish'\n",
        "images, labels = load_data(img_folder, img_height, img_width)\n",
        "\n",
        "# Convert labels to numerical format\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = len(np.unique(labels))\n",
        "\n",
        "# Preprocess and split the data\n",
        "X = np.array(images)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model with dynamic channel gating\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, img_channels)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Dynamic channel gating layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flatten the model and add dense layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Image data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255  # Add normalization\n",
        ")\n",
        "\n",
        "# Train the model with data augmentation\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
        "    steps_per_epoch=len(X_train) / batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot training history (accuracy and loss in one graph)\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.title('Training History')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Dr3wRqli_-x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIX9IoeKt7pa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVxTQLkk0c3K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE4Yzi3FQrLH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSX3lQnQjlyY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzWCOoSVY3_2"
      },
      "outputs": [],
      "source": [
        "pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE4WXLh4YLQT"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bAPS2kR5zAuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6yMmHEa1671"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-hG3B8PLnwX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1QoOfM3W8QWz0-whPyPVWBjcWs-NOcTp6",
      "authorship_tag": "ABX9TyMdut2+jGb5UM1lxE+EeH84",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}